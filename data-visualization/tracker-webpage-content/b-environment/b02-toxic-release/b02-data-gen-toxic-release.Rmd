---
title: "Toxic Site Release"
subtite: "Data Gen: Exploring, Cleaning, Transforming (tract data)"
author: "Meg Grzybowski, Grant Gibson"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  word_document:
  html_document:
    keep_md: yes
    df_print: paged
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r rmarkdown setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, 
                      warning=FALSE, 
                      message=FALSE) # formatting
```

```{r library setup, include=FALSE}
# devtools::install_github("psrc/psrcplot",
#                          force=TRUE)
library(tidyverse)
library(psrcelmer)
library(psrccensus)
library(psrcplot)
library(rlang) #required for psrccensus
library(emmeans) #required for rlang
library(magrittr)

library(vtable) #summary stats
library(forcats) #for factor re-leveling

library(odbc) #connect to ElmerGeo
library(DBI) #connect to ElmerGeo
library(sf)
library(leaflet)
library(leafem) #home button
library(htmlwidgets) #save visuals as html
library(ggspatial)
library(lubridate) #year formatting
library(readxl)
library(summarytools) ##freq/ctable functions

install_psrc_fonts()
library(showtext) #trying to fix PSRC font issues
library(sysfonts) #required for showtext
library(showtextdb) #required for showtext

library(here)
```

```{r sources}

# reference supplemental script with supporting settings/functions
source(here::here('data-visualization/equity-tracker-supplemental-script.R'))
```

```{r variables setup}

file_names <- list(base_dir = 'Y:/Equity Indicators/tracker-webpage-content',
                   theme_dir = 'b-environment',
                   ind_dir = 'b02-toxic-release',
                   chart = 'b02-toxic-release-chart-data',
                   map = 'b02-toxic-release-map-data')

folder_path <- file.path(file_names$base_dir,
                         file_names$theme_dir,
                         file_names$ind_dir,
                         "raw-data")

# set the variables
var_name <- "Toxic Release Exposure"
year <- 2024
years <- c(2014, 2019, 2024)
data <- 1:3 #number of datasets in raw_data list - to iterate through
```

**Toxic Release Site Inventory**

# Download data 
## Primary data 
Data comes from [EPA](https://www.epa.gov/toxics-release-inventory-tri-program). Separate CSVs at the point-level geography are available [manual download](https://www.epa.gov/toxics-release-inventory-tri-program/tri-basic-data-files-calendar-years-1987-present) for 1y increments, updated annually, with the most recent year being 2023.

```{r, include=FALSE}
# Data for this indicator comes from GIS buffer analysis
# Stefan Coe, Brian Lee, and Meg Grzybowski worked to identify point sources, create buffers around those sources, and then weight the amount of chemical emissions (accounting for multiple sources in one location and adding the compounding impacts). 
# The gdb files live here: W:\gis\projects\Megan\TRI_stefan.gdb
# Current method calculates pounds of release per sq ft

folder_path <- "Y:/Equity Indicators/tracker-webpage-content/b-environment/b02-toxic-release/raw-data/output"
toxic_release <- read.csv(file.path(folder_path,"toxic_release.csv"))

# convert release from lb/sq ft to lb/acre
toxic_release$release_acres <- toxic_release$on_site_release_total_exposure * 43560
```
\
Although there are innumerable possible data sets, the data sets we will be using will span 2010-2024 (most current data).


## Additional data

### equity quintile data and 2010-20 crosswalk file 

* low, low medium, etc.) at the tract-level for each equity focus group for the years that correspond to the toxic release data (2014, 2019, 2024
* for the 2010-2024 toxic release data set
```{r, include=FALSE}
# Elmer data sets - equity quintile tracts using psrcelmer() and crosswalk
equity_tracts <- get_table(schema="equity", tbl_name="v_tract_shares")
table(equity_tracts$data_year)

crosswalk_10_20 <- get_table(schema="census",
                             tbl_name="v_geo_relationships_tracts")
```

### tract spatial file
for mapping most recent data
```{r census tract spatial data - for tract data, include=FALSE}
# Connecting to ElmerGeo for census geographies through Portal----
arc_service <- "https://services6.arcgis.com/GWxg6t7KXELn1thE/arcgis/rest/services"

tracts20.url <- file.path(arc_service, "Census_Tracts_2020/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson")
tracts10.url <- file.path(arc_service, "Census_Tracts_2010/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson")

tracts20.lyr <- st_read(tracts20.url)
tracts10.lyr <- st_read(tracts10.url)

nrow(tracts20.lyr) #919
nrow(tracts10.lyr) #773
```

# Explore data
The data spans two census geography time frames - 2010 and 2020. Because the toxic release data is available at the point source location, they were translated to 2010 and 2020 geographies, depending on the data year (2010 geographies: 2010-2019; 2020 geographies: 2020-), each of which are assigned one of the 5 quintile categories for each of the 6 equity demographic groups.
```{r, include=FALSE}
# check number of rows in data set
nrow(toxic_release) #8358

# to check the field names and data class
str(toxic_release)
table(toxic_release$year)
```
Because the toxic release data is released yearly, we have chosen to start at 2010 through the most recent data set that corresponds to our equity demographic groups (available 2024). Because there is exposure data released every year, we match it with the corresponding equity demographic data, also available every year (but in overlapping 5-year time spans).

# Finalize data set
This step is included so that the data set and variable of interest and year variable are named in a consistent way for downstream processing. Review the field names in your data set to insert into the code below. You may need to add additional pipes to make any adjustments.
```{r, include=FALSE}
toxic_release$geoid <- as.character(toxic_release$geoid)  # to align data types for joining to tracts

toxic_release <- toxic_release %>% 
  mutate(data_year=year) %>% #rename field to be consistent with workflow
  select(-year)
```

## Most Recent Data
### Map
#### Join recent data to spatial file
```{r, include=FALSE}
# filter to most recent toxic release data
toxic_release_recent <- toxic_release %>% 
  dplyr::filter(data_year == year)

# join base 2020 geographic data to toxic release data 
data_tract <- merge(tracts20.lyr, toxic_release_recent,
                    by.x="geoid20",
                    by.y="geoid", 
                    all.x=TRUE) %>% 
  #dplyr::mutate(estimate = on_site_release_total_exposure)
  dplyr::mutate(estimate = release_acres)

# data_tract <- data_tract %>% 
#   dplyr::mutate(estimate_prelog=as.numeric(release_acres), # rename value variable for consistency
#                 estimate=log(estimate_prelog+1)) 
```

```{r tract data map}
# set map extent (in supplemental script)

# set up palettes
psrc_palette <- leaflet::colorNumeric(palette=psrc_colors$purples_inc,
                                      domain = data_tract$estimate)

# set the variable
var_name <- "Toxic Site Release\n(pounds per acre)"

# map settings
tract_map <- leaflet() %>%
  leaflet::addMapPane(name = "polygons", zIndex = 410) %>%
  leaflet::addMapPane(name = "maplabels", zIndex = 500) %>% # higher zIndex rendered on top
  leaflet::addProviderTiles("CartoDB.VoyagerNoLabels") %>%
  leaflet::addProviderTiles("CartoDB.VoyagerOnlyLabels",
                            options = leaflet::leafletOptions(pane = "maplabels"),
                            group = "Labels") %>%
  addPolygons(data=data_tract,
              fillColor = psrc_palette(data_tract$estimate),
              stroke=FALSE, 
              smoothFactor = 0.2,
              fillOpacity = 0.7,
              group = var_name,
              label = round(data_tract$estimate, digits=1)) %>%

  # legends
  addLegend_decreasing(pal = psrc_palette,
                       values = data_tract$estimate,
                       position = "bottomright",
                       title = var_name,
                       group = var_name,
                       opacity = 0.7,
                       decreasing = TRUE,
                       labFormat = labelFormat()) %>% 
  
  #set view extent
  leaflet::setView(lng=map.lon, lat=map.lat, zoom=map.zoom) %>% 
  addEasyButton(easyButton(
    icon = htmltools::span(class = "globe", htmltools::HTML("&#127758;")),  #&#127760; (another emoji option) #"fa-globe", (font awesome icon no longer works because of the conversion to Poppins font below)   
    title ="Region",
    onClick=JS("function(btn, map){map.setView([47.615,-122.257],8.5); }")))

# fix the legend NA placement (https://github.com/rstudio/leaflet/issues/615)
css_fix <- "div.info.legend.leaflet-control br {clear: both;} html * {font-family: Poppins !important;}" # CSS to correct spacing and font family
html_fix <- htmltools::tags$style(type = "text/css", css_fix)  # Convert CSS to HTML
tract_map %<>% htmlwidgets::prependContent(html_fix)

# print map
tract_map
```

### Missing Data
This step is dependent on your data set. If you have NAs you can use this step to visualize where in the region the NAs are occurring. If you do not have any NAs, you can skip this section and move on to the 'Descriptive Statistics' section.

#### Isolate NA or missing data
```{r}
# join NA data to the shapefile to map
data_tract_na <- data_tract %>% 
  filter(is.na(estimate))

nrow(data_tract_na) #240 tracts
```

```{r missing tract map}
# set up palettes
psrc_palette <- leaflet::colorNumeric(palette=psrc_colors$purples_inc,
                                      domain = data_tract$estimate)

# map settings
tract_map <- leaflet() %>%
  leaflet::addMapPane(name = "polygons", zIndex = 410) %>%
  leaflet::addMapPane(name = "maplabels", zIndex = 500) %>% # higher zIndex rendered on top
  leaflet::addProviderTiles("CartoDB.VoyagerNoLabels") %>%
  leaflet::addProviderTiles("CartoDB.VoyagerOnlyLabels",
                            options = leaflet::leafletOptions(pane = "maplabels"),
                            group = "Labels") %>%
  leaflet::addLayersControl(baseGroups = var_name,
                   overlayGroups = "missing data",
                   options = layersControlOptions(collapsed = FALSE)) %>%
  
  addPolygons(data=data_tract,
              fillColor = psrc_palette(data_tract$estimate),
              stroke=FALSE, 
              smoothFactor = 0.2,
              fillOpacity = 0.7,
              group = var_name,
              label = round(data_tract$estimate, digits=1)) %>%
  addPolygons(data=data_tract_na,
              color = "red",
              stroke = TRUE, 
              weight = 3,
              smoothFactor = 0.5,
              fillOpacity = 0,
              group = "missing data") %>% 

  # legends
  addLegend_decreasing(pal = psrc_palette,
                       values = data_tract$estimate,
                       position = "bottomright",
                       title = var_name,
                       group = var_name,
                       opacity = 0.7,
                       decreasing = TRUE,
                       labFormat = labelFormat()) %>% 
  
  #set view extent
  leaflet::setView(lng=map.lon, lat=map.lat, zoom=map.zoom) %>% 
  addEasyButton(easyButton(
    icon = htmltools::span(class = "globe", htmltools::HTML("&#127758;")),  #&#127760; (another emoji option) #"fa-globe", (font awesome icon no longer works because of the conversion to Poppins font below)   
    title ="Region",
    onClick=JS("function(btn, map){map.setView([47.615,-122.257],8.5); }")))

# fix the legend NA placement (https://github.com/rstudio/leaflet/issues/615)
css_fix <- "div.info.legend.leaflet-control br {clear: both;} html * {font-family: Poppins !important;}" # CSS to correct spacing and font family
html_fix <- htmltools::tags$style(type = "text/css", css_fix)  # Convert CSS to HTML
tract_map %<>% htmlwidgets::prependContent(html_fix)

# print map
tract_map
```

### Descriptive Statistics
The following descriptive statistics reflect the census tracts that have values - the `r na_rows_num` census tracts with NAs have been removed. These are not weighted by population numbers. 
```{r}
data_tract_nona <- data_tract %>% 
  filter(!is.na(estimate))

summary(data_tract_nona$estimate)
```

```{r, include=FALSE}
# data_tract_nona_weight <- data_tract_nona %>% 
#   mutate(tot_age = estimate*total_pop10,
#          reg_tot = sum(tot_age),
#          tot_pop = sum(total_pop10),
#          est_weight_avg = reg_tot/tot_pop)

# distrib <- rep(data_tract_nona$estimate, data_tract_nona$total_pop10)
distrib <- rep(data_tract_nona$estimate)

med.value <- median(distrib) #0.08020793
```
*Median:* `r med.value`
\
\

#### Histogram
A histogram is a visual representation of the distribution of a dataset...The y-axis shows how frequently the values on the x-axis occur in the data, while the bars group ranges of values or continuous categories on the x-axis [(source)](https://www.datacamp.com/tutorial/make-histogram-basic-r).  
```{r}
hist(distrib)
```
\

#### Boxplot
A boxplot helps to visualize a quantitative variable by displaying five common location summary (minimum, median, first and third quartiles and maximum) and any observation that was classified as a suspected outlier using the interquartile range (IQR) criterion [(source)](https://statsandr.com/blog/outliers-detection-in-r/).  
```{r}
boxplot(distrib, horizontal = TRUE)
```
\

#### Outliers
The IQR criterion means that all observations above or below the first and third quartile respectively, and IQR is the difference between the third and first quartile) are considered as potential outliers by R [(source)](https://statsandr.com/blog/outliers-detection-in-r/).  
```{r}
# outliers <- boxplot.stats(distrib)$out
# outlier_rle <- rle(outliers)
# outlier_df <- data.frame(unclass(outlier_rle)) %>%
#   # rename(population = lengths,
#   #        health_in = values) %>%
#   arrange(values)
# 
# outlier_df
```
\

##### *Check outliers* (OPTIONAL)
The following steps are specific to the life expectancy dataset and may or may not be applicable depending on the data.

###### Identify census tracts with outliers
```{r include=FALSE}
# outlier_values <- outlier_df[,2]
# 
# data_tract_nona_weight_outliers <- data_tract_nona_weight %>% 
#   dplyr::filter(estimate %in% outlier_values)
# 
# num_outliers <- nrow(data_tract_nona_weight_outliers)
```
There are `r num_outliers` tracts that have outliers. 
\
\

###### Outliers by Displacement Risk score
This check uses the displacement risk data, which is mapped to 2010 census tracts. This will help determine if there is a connection between displacement risk and `r indicator_measure`.
```{r displacement risk data, inlcude=FALSE}
# Connecting to Portal for displacement tract geographies ----
displacement.url <- "https://services6.arcgis.com/GWxg6t7KXELn1thE/arcgis/rest/services/Displacement_Risk_Data/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson"

displacement.lyr <-st_read(displacement.url)
# head(displacement.lyr)
# plot(displacement.lyr$geometry)
# class(displacement.lyr$geoid10)

displacement_simp <- displacement.lyr %>%
  dplyr::select(geoid10,
                risk_score) %>% 
  as_tibble() %>% 
  dplyr::select(-geometry)
```

```{r, include=FALSE}
# data_tract_nona_weight_outliers %<>% 
#   dplyr::mutate(geoid=trimws(geoid10))
# 
# # join outlier tract datas to spatial dispalcement tract data to isolate tracts with outlier data
# data_tract_risk_outliers <- merge(x=displacement_simp, 
#                                       y=data_tract_nona_weight_outliers,
#                                       by.x="geoid10",
#                                       by.y="geoid",
#                                       all.y=TRUE)
# head(data_tract_risk_outliers)
# # class(data_tract_risk_outliers)
# # plot(data_tract_risk_outliers$geometry)
# nrow(data_tract_risk_outliers) #7
# pop_outliers <- as.numeric(sum(data_tract_risk_outliers$total_pop10, na.rm = T)) #33152
# pop_outliers_num <- label_comma()(pop_outliers)
```
There are `r pop_outliers_num` people (2020 Decennial Census) in these outlier tracts.
\
\
```{r}
# compare the two measures
# plot(data_tract_risk_outliers$risk_score, 
#      data_tract_risk_outliers$estimate)
```

```{r}
# # this will be different for each indicator - the code and the text included below...
# # based on the plot in the last chunk, this code is meant to isolate outlier(s) - in this case it filters for the outliers with high risk scores and high life expectancy
# 
# # outlier #1
# data_tract20_outliers_1 <- data_tract_risk_outliers %>% 
#   filter(risk_score > 50)
# 
# # code to look at the scores and census tracts that are outliers
# data_tract20_outliers_1
# 
# # outlier #2
# data_tract20_outliers_2 <- data_tract_risk_outliers %>% 
#   filter(risk_score < 17)
# 
# # code to look at the scores and census tracts that are outliers
# data_tract20_outliers_2
# 
# # To locate the census tracts on the map, its easy to use the Data Portal (https://psrc-psregcncl.hub.arcgis.com/datasets/census-tracts-2020/explore?location=47.506129%2C-121.980700%2C9.23) - just filter on the geoid20 field. 
```


# **MAP .rda**
Save final data set (.rda) for map
```{r, include=FALSE}
# This is the data set used to create the map of the most recent data. For this data set, there is one additional transformation that is needed before saving it for final visualization in the 'vis' script. If there are any edits they should be made before saving it as an .rda. If not, you can skip this code chunk. 

# Because the measure (toxic release exposure) DOES account for the population of the tract, it's already been normalized and doesn't need to be weighted to aggregate to the region level. The map is going to visualize 2024 data in 2020 geographies.
```

```{r, region and county numbers for map labels}
# calculating data by county 
county_tract_data <- data_tract %>% 
  st_drop_geometry() %>%  #to remove spatial component
  dplyr::group_by(county_name) %>% 
  dplyr::mutate(cnty_estimate=mean(estimate, na.rm = TRUE)) %>% #calculate value by county
  dplyr::distinct(county_name, cnty_estimate)

# calculating data by region
reg_tract_data <- data_tract %>% 
  st_drop_geometry() %>%  #to remove spatial component
  dplyr::mutate(reg_estimate=mean(estimate, na.rm = TRUE)) %>%  #calculate value for region
  dplyr::distinct(reg_estimate)

# add region data to county data
county_reg_data <- county_tract_data %>% 
  mutate(reg_estimate=reg_tract_data$reg_estimate)

# merge tract, county, and region data into one data set 
data_tract <- merge(data_tract, county_reg_data,
                    by.x="county_name",
                    by.y="county_name",
                    all.x=TRUE)
```

```{r}
# save final data set as .rda
save(data_tract, file = file.path(file_names$base_dir,
                                  file_names$theme_dir,
                                  file_names$ind_dir, 
                                  "update",
                                  "rda-data",
                                  paste0(file_names$map,'.rda')))
```

# Explore data by equity quintile
## Join primary data to equity quintiles
```{r, include=FALSE}
# primary data - toxic release ----
head(toxic_release)
unique(toxic_release$data_year)

# add county information
toxic_release <- toxic_release %>%
  dplyr::mutate(county_code=substr(geoid, 3, 5), # add county to tract level data
                county_name = case_when(county_code=="033" ~"King",
                                        county_code=="035" ~"Kitsap",
                                        county_code=="053" ~"Pierce",
                                        county_code=="061" ~"Snohomish"))

# equity quintiles ----
head(equity_tracts)
unique(equity_tracts$data_year)

# the differences for these data - toxic release (2010-2024), equity tracts (2009-2024)
# will try an inner join based on year and geoid - removes 2020 from data because not available for toxic release, but should be available?

# toxic_release_equity_tracts <- inner_join(toxic_release, equity_tracts,
#                                           by = c("year" = "data_year", 
#                                                  "geoid" = "geoid"))
merge <- merge(equity_tracts, toxic_release, 
               by.x=c("data_year", "geoid"),
               by.y=c("data_year","geoid"),
               all.x=TRUE)

unique(merge$data_year) #2009-2024
# need to remove 2009 - not included in toxic release data
# 
toxic_release_equity_tracts <- merge %>% 
  dplyr::filter(data_year!=2009)

unique(toxic_release_equity_tracts$county) #5
# table(toxic_release_equity_tracts$data_year,toxic_release_equity_tracts$county)
# table(equity_tracts$data_year,equity_tracts$county)

# test <- toxic_release_equity_tracts %>% 
#   dplyr::filter(data_year==2021,
#                 geoid=="53035080500")

# separate 2010 and 2020 geographies
toxic_release_equity_10 <- toxic_release_equity_tracts %>% 
  dplyr::filter(data_year<2020) #15440

n_distinct(toxic_release_equity_10$geoid) #772 - check to make sure in correct geography

toxic_release_equity_20 <- toxic_release_equity_tracts %>% 
  dplyr::filter(data_year>=2020) #3676

n_distinct(toxic_release_equity_20$geoid) #919 - check to make sure in correct geography

tot_row <- (772*2*10)+(919*2*4)
```
The data set should include about twice the number of census tracts in the region - census tracts are listed twice - once as part of the region and another as part of their corresponding county. Because toxic release data is available for every year, starting in 2010, the data set should have a row for every 2010 tract (twice, for 10 years) and every 2020 tract (twice, for 4 years) = `r tot_row`.

## Transform/pivot
The data sets need to be cleaned and pivoted to a longer table so that there is only one field for the 6 different equity categories, instead of one field for each.
```{r, include=FALSE}
str(toxic_release_equity_tracts)

# clean/simplify data sets
data_equity_quintile <- toxic_release_equity_tracts %>% 
  dplyr::mutate(data_year=format(data_year,format="%Y"))

# pivot data set so that there is one column with quintile designation
data_equity_pivot <- data_equity_quintile %>% 
   pivot_longer(cols = poc_quintile:lep_quintile,
               names_to = "equity_group",
               values_to = "quintile")
```

```{r}
# check data sets
nrow(data_equity_pivot) #147780
```

These data sets should include records for:

* 2 geographies (region and whichever county the tract belongs to) x # census tracts (~773 for 2010-2019, ~919 for 2020-2024)
* 6 equity focus groups (disability and lep are not available in for 2010, lep not available in 2015 - but still show up as NA)


## Calculations
### Calculate by county and region
The data are available at the census tract level but we want to calculate the average values across the census tracts grouping by the 6 equity/5 quintile groups/5 geographies (4 counties + region). For some indicators, such as life expectancy, we may also want to weight the values using the ACS population estimates. 

The step of calculating by county/equity group/quintile is important for all data sets. The weighting by population is optional depending on the data set - comment out or delete whichever doesn't fit your data set. 
```{r}
# if you did not weight your data set -----
data_tract <- data_equity_pivot %>%
  filter(!is.na(quintile)) %>% # necessary because of added na columns from pivot
  dplyr::group_by(county, data_year, equity_group, quintile) %>%
  dplyr::summarise(estimate=(mean(release_acres, na.rm=TRUE)), .groups = 'drop')

# check data set
nrow(data_tract) #2040
table(data_tract$data_year)
# 5 geography * 6 equity groups * 5 quintiles = 150
```
This data set should include records for: 

* 5 geographies: 4 PSRC counties + region
* 1 year (for now, until 2012, 2016, and 2024 are available)
* ~6 equity focus groups (depends on the years for disability an lep)
* 5 equity quintiles


### Address "Low - Low Medium" quintile group
This code was added because of Kitsap/LEP data - there were too many tracts with 0, so we combined the bottom two quintiles into low - low medium. This change requires some additional processing so that all of the tracts (bottom 40%) in this combined quintile category are averaged and this average value is assigned to separate 'low' and 'low medium' quintile categories. 
```{r}
# nrow(data_tract) #571
# unique(data_tract$quintile) #6 quintiles because of additional "Low - Low Medium"

low_quintile <- data_tract %>%
  filter(quintile=="Low - Low Medium") %>% 
  rename(quintile_original=quintile) %>%
  mutate(quintile="Low") %>%  # quintile label that matches rest of data
  filter(county!="Region") # need to remove region from this because there should be enough tracts when all the tracts are combined to have separate low and low medium classifications
lowmed_quintile <- data_tract %>% 
  filter(quintile=="Low - Low Medium") %>%
  rename(quintile_original=quintile) %>%
  mutate(quintile="Low Medium") %>% # quintile label that matches rest of data
  filter(county!="Region") # need to remove region from this because there should be enough tracts when all the tracts are combined to have separate low and low medium classifications

low_lowmed <- rbind(low_quintile,
                    lowmed_quintile)
nrow(low_lowmed) #8 - 2016 for Kitsap, 2020 for Kitsap and Pierce, 2024 for Kitsap

# gather counties that have low - medium categorization
low_lowmed_counties <- unique(low_lowmed$county) #Kitsap and Pierce
low_lowmed_years <- unique(low_lowmed$data_year) #2016, 2020, 2024
low_lowmed_equity <- unique(low_lowmed$equity_group) #lep_quintile

other_data <- data_tract %>% 
  filter(quintile!="Low - Low Medium") %>% 
  mutate(quintile_original=quintile)
# nrow(other_data) #568

data_tract_comb <- rbind(low_lowmed, #8
                         other_data) #567

nrow(data_tract_comb) #575
unique(data_tract_comb$quintile) #5 quintiles

# remove rows where it is one of the "Low - Low Medium" quintiles AND the original quintile is "Low" or "Low Medium" - only want to keep the rows that are "Low"/"Low Medium" and they share a value
# data_full <- data_tract_comb %>% 
#   filter(!(county %in% low_lowmed_counties & 
#            data_year %in% low_lowmed_years &
#            equity_group %in% low_lowmed_equity &
#            (quintile_original=="Low" | 
#              quintile_original=="Low Medium"))) %>% 
#   select(-quintile_original) # not needed for visualization, originally kept for checking

data_full <- data_tract_comb %>% 
  select(-quintile_original) # not needed for visualization, originally kept for checking

# nrow(data_full) #575
table(data_full$quintile, data_full$county) #should not have extra in low and low medium quintile categories
table(data_full$data_year, data_full$quintile)
```


## Rename and factor
```{r}
# wrap/order labels ----
# variable ordering and label function in equity-tracker-supplemental-script.R
data_clean <- transform_data_labels_tract(data_full)
```

# **CHART .rda**
Save final data set for charts (.rda)
```{r}
# save final data set as .rda
save(data_clean, file = file.path(file_names$base_dir,
                                  file_names$theme_dir,
                                  file_names$ind_dir, 
                                  "update",
                                  "rda-data",
                                  paste0(file_names$chart,'.rda')))
```

<a href="#top">Back to top of the page</a>