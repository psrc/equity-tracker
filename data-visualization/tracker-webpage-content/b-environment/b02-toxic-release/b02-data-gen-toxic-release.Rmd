---
title: "Toxic Release"
subtite: "Data Gen: Exploring, Cleaning, Transforming (tract data)"
author: "Meg Grzybowski, Grant Gibson"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  word_document:
  html_document:
    keep_md: yes
    df_print: paged
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r rmarkdown setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, 
                      warning=FALSE, 
                      message=FALSE) # formatting
```

```{r library setup, include=FALSE}
# devtools::install_github("psrc/psrcplot",
#                          force=TRUE)
library(tidyverse)
library(psrcelmer)
library(psrccensus)
library(psrcplot)
library(psrctrends)
library(rlang) #required for psrccensus
library(emmeans) #required for rlang
library(magrittr)
library(ggplot2)

library(summarytools) #freq
library(vtable) #summary stats
library(table1)  #nice descriptive summary table
library(scales) #number formatting
library(ggpubr) #graphing - ggarrange fx
library(forcats) #for factor re-leveling
library(plotly) #for interactive charts

library(odbc) #connect to ElmerGeo
library(DBI) #connect to ElmerGeo
library(sf)
library(leaflet)
library(leafem) #home button
library(htmlwidgets) #save visuals as html
library(raster)
library(ggspatial)
library(lubridate) #year formatting
library(stringr) #add leading zero's
library(reshape2) #formatting data
library(readxl)
library(gridExtra)

install_psrc_fonts()
library(showtext) #trying to fix PSRC font issues
library(sysfonts) #required for showtext
library(showtextdb) #required for showtext
```

**Toxic Release Site Inventory**

# Download data 
## Primary data 
Data comes from [EPA](https://www.epa.gov/toxics-release-inventory-tri-program). Separate CSVs at the point-level geography are available [manual download](https://www.epa.gov/toxics-release-inventory-tri-program/tri-basic-data-files-calendar-years-1987-present) for 1y increments, updated annually, with the most recent year being 2023.

```{r, include=FALSE}
# Data for this indicator comes from GIS buffer analysis
# Stefan Coe, Brian Lee, and Meg Grzybowski worked to identify point sources, create buffers around those sources, and then weight the amount of chemical emissions (accounting for multiple sources in one location and adding the compounding impacts). 
# The gdb files live here: W:\gis\projects\Megan\TRI_stefan.gdb
# Current method calculates pounds of release per sq ft

folder_path <- "Y:/Equity Indicators/tracker-webpage-content/b-environment/b02-toxic-release/raw-data/output"
toxic_release <- read.csv(file.path(folder_path,"toxic_release.csv"))

# convert release from lb/sq ft to lb/acre
toxic_release$release_acres <- toxic_release$on_site_release_total_exposure * 43560
```
\
Although there are innumerable possible data sets, the data sets we will be using will span 2010-2022 (most current data).


## Additional data

### equity quintile data and 2010-20 crosswalk file 

* low, low medium, etc.) at the tract-level for each equity focus group for the years that correspond to the toxic release data (2011, 2016, 2021
* for the 2010-2022 toxic release data set
```{r, include=FALSE}
# Elmer data sets - equity quintile tracts using psrcelmer() and crosswalk
equity_tracts <- get_table(schema="equity", tbl_name="v_tract_shares")
table(equity_tracts$data_year)

crosswalk_10_20 <- get_table(schema="census",
                             tbl_name="v_geo_relationships_tracts")
```

### tract spatial file
for mapping most recent data
```{r census tract spatial data - for tract data, include=FALSE}
# Connecting to ElmerGeo for census geographies through Portal----
tracts20.url <- "https://services6.arcgis.com/GWxg6t7KXELn1thE/arcgis/rest/services/Census_Tracts_2020/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson"
tracts10.url <- "https://services6.arcgis.com/GWxg6t7KXELn1thE/arcgis/rest/services/Census_Tracts_2010/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson"

tracts20.lyr<-st_read(tracts20.url)
tracts10.lyr<-st_read(tracts10.url)

nrow(tracts20.lyr) #919
nrow(tracts10.lyr) #773
```

# Explore data
The data spans two census geography time frames - 2010 and 2020. Because the toxic release data is available at the point source location, they were translated to 2010 and 2020 geographies, depending on the data year (2010 geographies: 2010-2019; 2020 geographies: 2020-), each of which are assigned one of the 5 quintile categories for each of the 6 equity demographic groups.
```{r, include=FALSE}
# check number of rows in data set
nrow(toxic_release) #7206
```
Because the toxic release data is released yearly, we have chosen to start at 2010 through the most recent data set that corresponds to our equity demographic groups (available 2021). Because there is exposure data released every year, we match it with the corresponding equity demographic data, also available every year (but in overlapping 5-year time spans).

```{r, include=FALSE}
# to check the field names and data class
str(toxic_release)

toxic_release$geoid <- as.character(toxic_release$geoid)  # to align data types for joining to tracts
```

## Most Recent Data
### Map
#### Join recent data to spatial file
```{r, include=FALSE}
# filter to most recent toxic release data
toxic_release_22 <- toxic_release %>% 
  dplyr::filter(year==2022)
# join base 2020 geographic data to toxic release data 
data_tract <- merge(tracts20.lyr, toxic_release_22,
                    by.x="geoid20",
                    by.y="geoid", 
                    all.x=TRUE) %>% 
  #dplyr::mutate(estimate = on_site_release_total_exposure)
  dplyr::mutate(estimate = release_acres)

# data_tract <- data_tract %>% 
#   dplyr::mutate(estimate_prelog=as.numeric(release_acres), # rename value variable for consistency
#                 estimate=log(estimate_prelog+1)) 
```

```{r}
# https://stackoverflow.com/questions/40276569/reverse-order-in-r-leaflet-continuous-legend - to get legend high-low with correct color order
addLegend_decreasing <-
  function (map,
            position = c("topright", "bottomright", "bottomleft",
                         "topleft"),
            pal,
            values,
            na.label = "NA",
            bins = 7,
            colors,
            opacity = 0.5,
            labels = NULL,
            labFormat = labelFormat(),
            title = NULL,
            className = "info legend",
            layerId = NULL,
            group = NULL,
            data = getMapData(map),
            decreasing = FALSE) {
    position <- match.arg(position)
    type <- "unknown"
    na.color <- NULL
    extra <- NULL
    if (!missing(pal)) {
      if (!missing(colors))
        stop("You must provide either 'pal' or 'colors' (not both)")
      if (missing(title) && inherits(values, "formula"))
        title <- deparse(values[[2]])
      values <- evalFormula(values, data)
      type <- attr(pal, "colorType", exact = TRUE)
      args <- attr(pal, "colorArgs", exact = TRUE)
      na.color <- args$na.color
      if (!is.null(na.color) &&
          col2rgb(na.color, alpha = TRUE)[[4]] ==
          0) {
        na.color <- NULL
      }
      if (type != "numeric" && !missing(bins))
        warning("'bins' is ignored because the palette type is not numeric")
      if (type == "numeric") {
        cuts <- if (length(bins) == 1)
          pretty(values, bins)
        else
          bins
        
        if (length(bins) > 2)
          if (!all(abs(diff(bins, differences = 2)) <=
                   sqrt(.Machine$double.eps)))
            stop("The vector of breaks 'bins' must be equally spaced")
        n <- length(cuts)
        r <- range(values, na.rm = TRUE)
        cuts <- cuts[cuts >= r[1] & cuts <= r[2]]
        n <- length(cuts)
        p <- (cuts - r[1]) / (r[2] - r[1])
        extra <- list(p_1 = p[1], p_n = p[n])
        p <- c("", paste0(100 * p, "%"), "")
        if (decreasing == TRUE) {
          colors <- pal(rev(c(r[1], cuts, r[2])))
          labels <- rev(labFormat(type = "numeric", cuts))
        } else{
          colors <- pal(c(r[1], cuts, r[2]))
          labels <- rev(labFormat(type = "numeric", cuts))
        }
        colors <- paste(colors, p, sep = " ", collapse = ", ")
        
      }
      else if (type == "bin") {
        cuts <- args$bins
        n <- length(cuts)
        mids <- (cuts[-1] + cuts[-n]) / 2
        if (decreasing == TRUE) {
          colors <- pal(rev(mids))
          labels <- rev(labFormat(type = "bin", cuts))
        } else{
          colors <- pal(mids)
          labels <- labFormat(type = "bin", cuts)
        }
        
      }
      else if (type == "quantile") {
        p <- args$probs
        n <- length(p)
        cuts <- quantile(values, probs = p, na.rm = TRUE)
        mids <- quantile(values, probs = (p[-1] + p[-n]) / 2,
                         na.rm = TRUE)
        if (decreasing == TRUE) {
          colors <- pal(rev(mids))
          labels <- rev(labFormat(type = "quantile", cuts, p))
        } else{
          colors <- pal(mids)
          labels <- labFormat(type = "quantile", cuts, p)
        }
      }
      else if (type == "factor") {
        v <- sort(unique(na.omit(values)))
        colors <- pal(v)
        labels <- labFormat(type = "factor", v)
        if (decreasing == TRUE) {
          colors <- pal(rev(v))
          labels <- rev(labFormat(type = "factor", v))
        } else{
          colors <- pal(v)
          labels <- labFormat(type = "factor", v)
        }
      }
      else
        stop("Palette function not supported")
      if (!any(is.na(values)))
        na.color <- NULL
    }
    else {
      if (length(colors) != length(labels))
        stop("'colors' and 'labels' must be of the same length")
    }
    legend <-
      list(
        colors = I(unname(colors)),
        labels = I(unname(labels)),
        na_color = na.color,
        na_label = na.label,
        opacity = opacity,
        position = position,
        type = type,
        title = title,
        extra = extra,
        layerId = layerId,
        className = className,
        group = group
      )
    invokeMethod(map, data, "addLegend", legend)
  }

```

```{r tract data map}
# set map extent
map.lat<- 47.615
map.lon<- -122.257
map.zoom<- 8.5

# set up palettes
psrc_palette <- leaflet::colorNumeric(palette=psrc_colors$purples_inc,
                                      domain = data_tract$estimate)

# set the variable
var_name <- "Toxic Site Release\n(pounds per acre)"

# map settings
tract_map <- leaflet() %>%
  leaflet::addMapPane(name = "polygons", zIndex = 410) %>%
  leaflet::addMapPane(name = "maplabels", zIndex = 500) %>% # higher zIndex rendered on top
  leaflet::addProviderTiles("CartoDB.VoyagerNoLabels") %>%
  leaflet::addProviderTiles("CartoDB.VoyagerOnlyLabels",
                            options = leaflet::leafletOptions(pane = "maplabels"),
                            group = "Labels") %>%
  addPolygons(data=data_tract,
              fillColor = psrc_palette(data_tract$estimate),
              stroke=FALSE, 
              smoothFactor = 0.2,
              fillOpacity = 0.7,
              group = var_name,
              label = round(data_tract$estimate, digits=1)) %>%

  # legends
  addLegend_decreasing(pal = psrc_palette,
                       values = data_tract$estimate,
                       position = "bottomright",
                       title = var_name,
                       group = var_name,
                       opacity = 0.7,
                       decreasing = TRUE,
                       labFormat = labelFormat()) %>% 
  
  #set view extent
  leaflet::setView(lng=map.lon, lat=map.lat, zoom=map.zoom) %>% 
  addEasyButton(easyButton(
    icon = htmltools::span(class = "globe", htmltools::HTML("&#127758;")),  #&#127760; (another emoji option) #"fa-globe", (font awesome icon no longer works because of the conversion to Poppins font below)   
    title ="Region",
    onClick=JS("function(btn, map){map.setView([47.615,-122.257],8.5); }")))

# fix the legend NA placement (https://github.com/rstudio/leaflet/issues/615)
css_fix <- "div.info.legend.leaflet-control br {clear: both;} html * {font-family: Poppins !important;}" # CSS to correct spacing and font family
html_fix <- htmltools::tags$style(type = "text/css", css_fix)  # Convert CSS to HTML
tract_map %<>% htmlwidgets::prependContent(html_fix)

# print map
tract_map
```

### Missing Data
Life expectancy calculations can fluctuate considerably in smaller populations or populations experiencing low or no deaths for the year(s) being calculated. Because of these issues the Life Expectancy at birth calculation for the Census Tract geographies is suppressed for Census Tracts with a population (for the 5 years combined) of <5000 or a result with a Standard Error >2 or a record of <50 deaths for the time period. The Washington Department of Health, Center for Health Statistics estimates data gathered from death certificates to be 99% complete.

#### Isolate NA or missing data
```{r}
# join NA data to the shapefile to map
data_tract_na <- data_tract %>% 
  filter(is.na(estimate))

nrow(data_tract_na) #0 tracts
```

```{r missing tract map}
# set map extent
map.lat<- 47.615
map.lon<- -122.257
map.zoom<- 8.5

# set up palettes
psrc_palette <- leaflet::colorNumeric(palette=psrc_colors$purples_inc,
                                      domain = data_tract$estimate)

# set the variable
var_name <- "Toxic Release Exposure"

# map settings
tract_map <- leaflet() %>%
  leaflet::addMapPane(name = "polygons", zIndex = 410) %>%
  leaflet::addMapPane(name = "maplabels", zIndex = 500) %>% # higher zIndex rendered on top
  leaflet::addProviderTiles("CartoDB.VoyagerNoLabels") %>%
  leaflet::addProviderTiles("CartoDB.VoyagerOnlyLabels",
                            options = leaflet::leafletOptions(pane = "maplabels"),
                            group = "Labels") %>%
  leaflet::addLayersControl(baseGroups = var_name,
                   overlayGroups = "missing data",
                   options = layersControlOptions(collapsed = FALSE)) %>%
  
  addPolygons(data=data_tract,
              fillColor = psrc_palette(data_tract$estimate),
              stroke=FALSE, 
              smoothFactor = 0.2,
              fillOpacity = 0.7,
              group = var_name,
              label = round(data_tract$estimate, digits=1)) %>%
  addPolygons(data=data_tract_na,
              color = "red",
              stroke = TRUE, 
              weight = 3,
              smoothFactor = 0.5,
              fillOpacity = 0,
              group = "missing data") %>% 

  # legends
  addLegend_decreasing(pal = psrc_palette,
                       values = data_tract$estimate,
                       position = "bottomright",
                       title = var_name,
                       group = var_name,
                       opacity = 0.7,
                       decreasing = TRUE,
                       labFormat = labelFormat()) %>% 
  
  #set view extent
  leaflet::setView(lng=map.lon, lat=map.lat, zoom=map.zoom) %>% 
  addEasyButton(easyButton(
    icon = htmltools::span(class = "globe", htmltools::HTML("&#127758;")),  #&#127760; (another emoji option) #"fa-globe", (font awesome icon no longer works because of the conversion to Poppins font below)   
    title ="Region",
    onClick=JS("function(btn, map){map.setView([47.615,-122.257],8.5); }")))

# fix the legend NA placement (https://github.com/rstudio/leaflet/issues/615)
css_fix <- "div.info.legend.leaflet-control br {clear: both;} html * {font-family: Poppins !important;}" # CSS to correct spacing and font family
html_fix <- htmltools::tags$style(type = "text/css", css_fix)  # Convert CSS to HTML
tract_map %<>% htmlwidgets::prependContent(html_fix)

# print map
tract_map
```

### Descriptive Statistics
The following descriptive statistics reflect the census tracts that have values - the `r na_rows_num` census tracts with NAs have been removed. These are not weighted by population numbers. 
```{r}
data_tract_nona <- data_tract %>% 
  filter(!is.na(estimate))

summary(data_tract_nona$estimate)
```

**When weighted by tract populations.** 
```{r, include=FALSE}
# data_tract_nona_weight <- data_tract_nona %>% 
#   mutate(tot_age = estimate*total_pop10,
#          reg_tot = sum(tot_age),
#          tot_pop = sum(total_pop10),
#          est_weight_avg = reg_tot/tot_pop)

# distrib <- rep(data_tract_nona$estimate, data_tract_nona$total_pop10)
distrib <- rep(data_tract_nona$estimate)

med.value <- median(distrib) #80.74
```
*Median:* `r med.value`
\
\

#### Histogram
A histogram is a visual representation of the distribution of a dataset...The y-axis shows how frequently the values on the x-axis occur in the data, while the bars group ranges of values or continuous categories on the x-axis [(source)](https://www.datacamp.com/tutorial/make-histogram-basic-r).  
```{r}
hist(distrib)
```
\

#### Boxplot
A boxplot helps to visualize a quantitative variable by displaying five common location summary (minimum, median, first and third quartiles and maximum) and any observation that was classified as a suspected outlier using the interquartile range (IQR) criterion [(source)](https://statsandr.com/blog/outliers-detection-in-r/).  
```{r}
boxplot(distrib, horizontal = TRUE)
```
\

#### Outliers
The IQR criterion means that all observations above or below the first and third quartile respectively, and IQR is the difference between the third and first quartile) are considered as potential outliers by R [(source)](https://statsandr.com/blog/outliers-detection-in-r/).  
```{r}
# outliers <- boxplot.stats(distrib)$out
# outlier_rle <- rle(outliers)
# outlier_df <- data.frame(unclass(outlier_rle)) %>% 
#   rename(population = lengths,
#          health_in = values) %>% 
#   arrange(health_in)
# 
# outlier_df
```
\

##### *Check outliers*
The following steps are specific to the life expectancy dataset and may or may not be applicable depending on the data.

###### Identify census tracts with outliers
```{r include=FALSE}
# outlier_values <- outlier_df[,2]
# 
# data_tract_nona_weight_outliers <- data_tract_nona_weight %>% 
#   dplyr::filter(estimate %in% outlier_values)
# 
# num_outliers <- nrow(data_tract_nona_weight_outliers)
```
There are `r num_outliers` tracts that have outliers. 
\
\

###### Outliers by Displacement Risk score
This check uses the displacement risk data, which is mapped to 2010 census tracts. This will help determine if there is a connection between displacement risk and `r indicator_measure`.
```{r displacement risk data, inlcude=FALSE}
# Connecting to Portal for displacement tract geographies ----
displacement.url <- "https://services6.arcgis.com/GWxg6t7KXELn1thE/arcgis/rest/services/Displacement_Risk_Data/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson"

displacement.lyr <-st_read(displacement.url)
# head(displacement.lyr)
# plot(displacement.lyr$geometry)
# class(displacement.lyr$geoid10)

displacement_simp <- displacement.lyr %>%
  dplyr::select(geoid10,
                risk_score) %>% 
  as_tibble() %>% 
  dplyr::select(-geometry)
```

```{r, include=FALSE}
# data_tract_nona_weight_outliers %<>% 
#   dplyr::mutate(geoid=trimws(geoid10))
# 
# # join outlier tract datas to spatial dispalcement tract data to isolate tracts with outlier data
# data_tract_risk_outliers <- merge(x=displacement_simp, 
#                                       y=data_tract_nona_weight_outliers,
#                                       by.x="geoid10",
#                                       by.y="geoid",
#                                       all.y=TRUE)
# head(data_tract_risk_outliers)
# # class(data_tract_risk_outliers)
# # plot(data_tract_risk_outliers$geometry)
# nrow(data_tract_risk_outliers) #7
# pop_outliers <- as.numeric(sum(data_tract_risk_outliers$total_pop10, na.rm = T)) #33152
# pop_outliers_num <- label_comma()(pop_outliers)
```
There are `r pop_outliers_num` people (2020 Decennial Census) in these outlier tracts.
\
\
```{r}
# compare the two measures
# plot(data_tract_risk_outliers$risk_score, 
#      data_tract_risk_outliers$estimate)
```

```{r}
# # this will be different for each indicator - the code and the text included below...
# # based on the plot in the last chunk, this code is meant to isolate outlier(s) - in this case it filters for the outliers with high risk scores and high life expectancy
# 
# # outlier #1
# data_tract20_outliers_1 <- data_tract_risk_outliers %>% 
#   filter(risk_score > 50)
# 
# # code to look at the scores and census tracts that are outliers
# data_tract20_outliers_1
# 
# # outlier #2
# data_tract20_outliers_2 <- data_tract_risk_outliers %>% 
#   filter(risk_score < 17)
# 
# # code to look at the scores and census tracts that are outliers
# data_tract20_outliers_2
# 
# # To locate the census tracts on the map, its easy to use the Data Portal (https://psrc-psregcncl.hub.arcgis.com/datasets/census-tracts-2020/explore?location=47.506129%2C-121.980700%2C9.23) - just filter on the geoid20 field. 
```


# **MAP .rda**
Save final data set (.rda) for map
```{r, include=FALSE}
# This is the data set used to create the map of the most recent data. For this data set, there is one additional transformation that is needed before saving it for final visualization in the 'vis' script. If there are any edits they should be made before saving it as an .rda. If not, you can skip this code chunk. 

# Because the measure (toxic release exposure) DOES account for the population of the tract, it's already been normalized and doesn't need to be weighted to aggregate to the region level. The map is going to visualize 2022 data in 2020 geographies.

 
# head(tract.20) # to determine field names of population data frame
# tract.20.edit <- tract.20 %>% 
#   dplyr::mutate(pop20=estimate) # the life expectancy value is already 'estimate'
# 
# # merge 2020 acs population data to crosswalk file
# pop20_crosswalk <- merge(tract.20.edit, crosswalk_10_20, 
#                          by.x="GEOID",
#                          by.y="geoid20", 
#                          all.x=TRUE)
# 
# # calculate population by adding 2020 tracts that were split from 2010 tracts
# pop20 <- pop20_crosswalk %>% 
#   dplyr::group_by(geoid10) %>% 
#   dplyr::summarise(total_pop20=sum(pop20))
# 
# # merge 2020 population by 2010 tracts to life expectancy data - this is for eventual weighting (which may not be necessary depending on the indicator)
# data_tract <- merge(data_tract, pop20, 
#                     by.x="geoid10",
#                     by.y="geoid10", 
#                     all.x=TRUE)
```

```{r, region and county numbers for map labels}
# calculating data by county 
county_tract_data <- data_tract %>% 
  st_drop_geometry() %>%  #to remove spatial component
  dplyr::group_by(county_name) %>% 
  dplyr::mutate(cnty_estimate=mean(estimate)) %>% #calculate value by county
  dplyr::distinct(county_name, cnty_estimate)

# calculating data by region
reg_tract_data <- data_tract %>% 
  st_drop_geometry() %>%  #to remove spatial component
  dplyr::mutate(reg_estimate=mean(estimate)) %>%  #calculate value for region
  dplyr::distinct(reg_estimate)

# add region data to county data
county_reg_data <- county_tract_data %>% 
  mutate(reg_estimate=reg_tract_data$reg_estimate)

# merge tract, county, and region data into one data set 
data_tract <- merge(data_tract, county_reg_data,
                    by.x="county_name",
                    by.y="county_name",
                    all.x=TRUE)
```

```{r}
# set folder structure
base_dir <- 'Y:/Equity Indicators/tracker-webpage-content'
theme_dir <- 'b-environment'
ind_dir <- 'b02-toxic-release'
file_name <- 'b02-toxic-release-map-data'

# save final data set as .rda
save(data_tract, file = file.path(base_dir,
                                  theme_dir,
                                  ind_dir, "rda-data",
                                  paste0(file_name,'.rda')))
```

# Explore data by equity quintile
## Join primary data to equity quintiles
```{r, include=FALSE}
# primary data - toxic release ----
head(toxic_release)
unique(toxic_release$year)

# add county information
# toxic_release <- toxic_release %>%
#   dplyr::mutate(county_code=substr(geoid, 3, 5), # add county to tract level data
#                 county_name = case_when(county_code=="033" ~"King",
#                                         county_code=="035" ~"Kitsap",
#                                         county_code=="053" ~"Pierce",
#                                         county_code=="061" ~"Snohomish"))

# geoid is number, set it as character to join with equity quintile tract Elmer data
toxic_release <- toxic_release %>% 
  dplyr::mutate(geoid=as.character(geoid))

# equity quintiles ----
head(equity_tracts)
unique(equity_tracts$data_year)

# the differences for these data - toxic release (2010-2022), equity tracts (2009-2020)
# will try an inner join based on year and geoid - removes 2020 from data because not available for toxic release, but should be available?

# toxic_release_equity_tracts <- inner_join(toxic_release, equity_tracts,
#                                           by = c("year" = "data_year", 
#                                                  "geoid" = "geoid"))
merge <- merge(equity_tracts, toxic_release, 
               by.x=c("data_year", "geoid"),
               by.y=c("year","geoid"),
               all.x=TRUE)

unique(merge$data_year) #2009-2021
# need to remove 2009 - not included in toxic release data
# 
toxic_release_equity_tracts <- merge %>% 
  dplyr::filter(data_year!=2009)

unique(toxic_release_equity_tracts$county) #5
# table(toxic_release_equity_tracts$data_year,toxic_release_equity_tracts$county)
# table(equity_tracts$data_year,equity_tracts$county)

# test <- toxic_release_equity_tracts %>% 
#   dplyr::filter(data_year==2021,
#                 geoid=="53035080500")

# separate 2010 and 2020 geographies
toxic_release_equity_10 <- toxic_release_equity_tracts %>% 
  dplyr::filter(data_year<2020) #15440

n_distinct(toxic_release_equity_10$geoid) #772 - check to make sure in correct geography

toxic_release_equity_20 <- toxic_release_equity_tracts %>% 
  dplyr::filter(data_year>=2020) #3676

n_distinct(toxic_release_equity_20$geoid) #919 - check to make sure in correct geography

tot_row <- (772*2*10)+(919*2*2)
```
The data set should include about twice the number of census tracts in the region - census tracts are listed twice - once as part of the region and another as part of their corresponding county. Because toxic release data is available for every year, starting in 2010, the data set should have a row for every 2010 tract (twice, for 10 years) and every 2020 tract (twice, for 2 years) = `r tot_row`.

## Transform/pivot
The data sets need to be cleaned and pivoted to a longer table so that there is only one field for the 6 different equity categories, instead of one field for each.
```{r, include=FALSE}
# pivot data set so that there is one column with quintile designation
toxic_release_equity_tracts_pivot <- toxic_release_equity_tracts %>% 
   pivot_longer(cols = poc_quintile:lep_quintile,
               names_to = "equity_group",
               values_to = "quintile")
```

```{r}
# check data sets
nrow(toxic_release_equity_tracts_pivot) #114696
```

These data sets should include records for:

* 2 geographies (region and whichever county the tract belongs to) x # census tracts (~773 for 2010-2019, ~919 for 2020-2021)
* 6 equity focus groups (disability and lep are not available in for 2010, lep not available in 2015 - but still show up as NA)


## Calculations
### Calculate by region
The exposure values are available at the census tract level, but we want to calculate the regional average, using the census bureau's tract-level population estimates (2010, 2015, 2020).
```{r}
toxic_release_equity_tracts_pivot_reg_calc <- toxic_release_equity_tracts_pivot %>% 
  # filter(!is.na(quintile)) %>% #missing lep and disability data
  dplyr::group_by(data_year,equity_group, quintile) %>%
  summarise(exposure=(mean(exposure, na.rm=TRUE))) %>% 
  mutate(county="Region")

toxic_release_equity_tracts_pivot_reg_calc <- toxic_release_equity_tracts_pivot %>% 
  filter(county=="Region") %>% 
  dplyr::group_by(data_year,equity_group, quintile) %>%
  summarise(exposure=(mean(exposure, na.rm=TRUE))) %>% 
  mutate(county="Region")
```

```{r}
# check data sets
nrow(toxic_release_equity_tracts_pivot_reg_calc)
```
These data sets should include records for:

* 1 geography: region
* 6 equity focus groups (disability and lep are not available in for 2010, lep not available in 2015)
     * 2010: only 4 equity focus groups
     * 2015: only 5 equity focus groups
* 5 equity quintiles 
* 11 years


### Calculate by equity quintile/county (including region)
The exposure values are available at the census tract level but we want to calculate the average values by the 6 equity/5 quintile groups. 
```{r}
# calculations to get average exposure
toxic_release_equity_tracts_pivot_calc_cnty <- toxic_release_equity_tracts_pivot %>% 
  filter(!is.na(quintile)) %>% # necessary because of added na columns from pivot
  dplyr::group_by(county, data_year, equity_group, quintile) %>%
  dplyr::summarise(exposure=(mean(exposure, na.rm=TRUE)), .groups = 'drop')

# check data set
nrow(toxic_release_equity_tracts_pivot_calc_cnty)
```
This data sets should include records for:

* 4 geographies: 4 PSRC counties
* 6 equity focus groups
* 5 equity quintiles 
* 11 years


## Combine years into one data set
```{r}
# data_tract <- as.data.frame(rbind(toxic_release_equity_tracts_pivot_reg_calc,
#                                   toxic_release_equity_tracts_pivot_calc_cnty))

data_tract <- toxic_release_equity_tracts_pivot_calc_cnty %>% 
  dplyr::mutate(estimate_prelog=as.numeric(exposure), # rename value variable for consistency
                estimate=log(estimate_prelog+1)) %>% 
  dplyr::mutate(data_year_yr=as.character(data_year))

# check data set
str(data_tract)
```
This data set should include records for: 

* 5 geographies: 4 PSRC counties + region
* 3 years
* 6 equity focus groups
    * 2010: (subtracting) 2 missing focus groups(disability, lep) * 5 equity quintiles * 5 geographies
    * 2015: (subtracting) 1 missing focus group (lep) * 5 equity quintiles * 5 geographies
* 5 equity quintiles

### Address "Low - Low Medium" quintile group
This code was added because of Kitsap/LEP data - there were too many tracts with 0, so we combined the bottom two quintiles into low - low medium. This change requires some additional processing so that all of the tracts (bottom 40%) in this combined quintile category are averaged and this average value is assigned to separate 'low' and 'low medium' quintile categories. 
```{r}
# nrow(data_tract) #378
# unique(data_tract$quintile) #6 quintiles because of additional "Low - Low Medium"

low_quintile <- data_tract %>% 
  filter(quintile=="Low - Low Medium") %>% 
  rename(quintile_original=quintile) %>% 
  mutate(quintile="Low") %>% 
  filter(County.Name!="Region") # need to remove region from this because there should be enough tracts when all the tracts are combined to have separate low and low medium classifications
lowmed_quintile <- data_tract %>% 
  filter(quintile=="Low - Low Medium") %>%
  rename(quintile_original=quintile) %>%
  mutate(quintile="Low Medium") %>% 
  filter(County.Name!="Region") # need to remove region from this because there should be enough tracts when all the tracts are combined to have separate low and low medium classifications

low_lowmed <- rbind(low_quintile,
                    lowmed_quintile)
# nrow(low_lowmed) #4

# gather counties that have low - medium categorization
low_lowmed_counties <- unique(low_lowmed$County.Name) #Kitsap, Pierce
low_lowmed_years <- unique(low_lowmed$data_year) #2020
low_lowmed_equity <- unique(low_lowmed$equity_group) #lep_quintile

other_data <- data_tract %>% 
  filter(quintile!="Low - Low Medium") %>% 
  rename(quintile_original=quintile) %>% 
  mutate(quintile=quintile_original)
# nrow(other_data) #375

data_tract <- rbind(low_lowmed, #4
                    other_data) #375

nrow(data_tract) #379 - should be fewer because of duplicates (375)- low and low medium present in data set because of aggregation/calculations in previous steps - need to be removed and replaced with averaged values
# table(data_tract$quintile, data_tract$County.Name) #should not have extra in low and low medium quintile categories
# unique(data_tract$quintile) #5 quintiles

# remove rows where it is one of the "Low - Low Medium" quintiles AND the original quintile is "Low" or "Low Medium" - only want to keep the rows that are "Low"/"Low Medium" and they share a value
data_tract <- data_tract %>% 
  filter(!(County.Name %in% low_lowmed_counties & 
           data_year %in% low_lowmed_years &
           equity_group %in% low_lowmed_equity &
           (quintile_original=="Low" | 
             quintile_original=="Low Medium")))

# nrow(data_tract) #375
# table(data_tract$quintile, data_tract$County.Name) #should not have extra in low and low medium quintile categories
```

## Rename and factor
```{r}
# wrap/order labels ----
county_order <- c("Region", "King", "Kitsap", "Pierce", "Snohomish")

quintile_order <- c("Low", 
                    "Low\nMedium", 
                    "Medium", 
                    "Medium\nHigh", 
                    "High")

equity_group_order <- c("People of Color", 
                        "Households with Lower Income", 
                        "People with a Disability", 
                        "Households with Limited English Proficiency", 
                        "Households with Youth <18", 
                        "Households with Older Adults 65+")

# transforming data labels ----
data_clean <- data_tract %>% 
  # mutate(county=County.Name) %>%  #rename value variable for consistency
  mutate(county_ord = factor(county, levels=county_order)) %>%
  mutate(equity_group_ord = case_when(
    equity_group=="poc_quintile"~"People of Color",
    equity_group=="disability_quintile"~"People with a Disability",
    equity_group=="lep_quintile"~"Households with Limited English Proficiency",
    equity_group=="income_quintile"~"Households with Lower Income",
    equity_group=="youth_quintile"~"Households with Youth <18",
    equity_group=="older_quintile"~"Households with Older Adults 65+")) %>%
  mutate(equity_group_ord = factor(equity_group_ord, levels = equity_group_order)) %>% 
  mutate(quintile_ord = str_wrap(quintile, width=7)) %>%
  mutate(quintile_ord = factor(quintile_ord, levels = quintile_order))

# Minor edits to the data
# data_clean <- data_clean %>%
#   dplyr::mutate(estimate=as.numeric(exposure)) #rename value variable for consistency

# Sort the data to ensure the charts work
data_clean <- data_clean %>%
  arrange(county_ord, equity_group_ord, quintile_ord, data_year)
```


# **CHART .rda**
Save final data set for charts (.rda)
```{r}
# set folder structure
file_name <- 'b02-toxic-release-data'

# save final data set as .rda
save(data_clean, file = file.path(base_dir,
                                  theme_dir,
                                  ind_dir, "rda-data",
                                  paste0(file_name,'.rda')))
```

<a href="#top">Back to top of the page</a>