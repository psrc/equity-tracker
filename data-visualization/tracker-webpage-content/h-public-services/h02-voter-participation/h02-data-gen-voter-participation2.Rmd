---
title: "Voter Participation"
subtite: "Data Gen: Exploring, Cleaning, Transforming (tract data)"
author: "Mary Richards"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  word_document:
  html_document:
    keep_md: yes
    df_print: paged
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r rmarkdown setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, 
                      warning=FALSE, 
                      message=FALSE) # formatting
```

```{r library setup, include=FALSE}
# devtools::install_github("psrc/psrcplot",
#                          force=TRUE)
library(tidyverse)
library(psrcelmer)
library(psrccensus)
library(psrcplot)
library(psrctrends)
library(rlang) #required for psrccensus
library(emmeans) #required for rlang
library(magrittr)
library(ggplot2)

library(summarytools) #freq
library(vtable) #summary stats
library(table1)  #nice descriptive summary table
library(scales) #number formatting
library(ggpubr) #graphing - ggarrange fx
library(forcats) #for factor re-leveling
library(plotly) #for interactive charts

library(odbc) #connect to ElmerGeo
library(DBI) #connect to ElmerGeo
library(sf)
library(leaflet)
library(leafem) #home button
library(htmlwidgets) #save visuals as html
library(raster)
library(ggspatial)
library(lubridate) #year formatting
library(stringr) #add leading zero's
library(reshape2) #formatting data
library(readxl)
library(readr)
library(gridExtra)

install_psrc_fonts()
library(showtext) #trying to fix PSRC font issues
library(sysfonts) #required for showtext
library(showtextdb) #required for showtext
```

**Voter Participation**

# Download data 
## Primary data 
The data set referenced in this script is generated from the [Washington Secretary of State elections](https://www.sos.wa.gov/elections#data_research) voter turnout data. These data sets provide data at the precinct-level, which is then translated to census geographies and related to the distribution/concentration of the six equity demographic groups of interest. 
\
\
Unfortunately the data for each major election year is not consistently formatted on the [website's data page](https://www.sos.wa.gov/elections/data-research/election-data-and-maps/election-results-and-voters-pamphlets). It requires a large amount of processing to get it to the correct format for each year of interest. 

### 2016 data
The process/code below is adapted from the displacement risk work done in 2018 ("Y:/VISION 2050/Data/Displacement/Displacement_Risk_Script"). Because the Secretary of State does not aggregate it to the state level, it is required to find each county's election data separately, then combine into one region-wide precinct-level dataset so that it can be translated to census tracts. 
```{r}
# Get 2016 presidential election votes by precinct ---------------------
# All of these datasets are saved to: 
data_folder <- "Y:/Equity Indicators/tracker-webpage-content/h-public-services/h02-voter-participation/raw-data/2016"

# 1. King County -----
## Access: https://kingcounty.gov/en/legacy/depts/elections/results/2016/201611.aspx > Final precinct level election results > Comma delimited file (2016_General_-_Election_Results_by_precinct__complete_eCanvass_dataset_.csv)
## Saved as:  2016_King_by_precinct.csv
king_el <- read_csv(file.path(data_folder,"2016_King_by_precinct.csv"))

king_data <- king_el %>%
  mutate(Race = factor(Race),
         CounterType = factor(CounterType)) %>%
  filter(Race == "US President & Vice President",
         CounterType %in% c("Registered Voters", "Times Counted"))%>%
  spread(key = CounterType, value = SumOfCount) %>% #like pivot wider
  mutate(Registered = `Registered Voters`,
         SumOfCount = `Times Counted`,
         County = factor("King"))%>%
  dplyr::select(County, Precinct, Registered, SumOfCount) 


# 2. Kitsap County -----
## Access: http://results.vote.wa.gov/results/20161108/kitsap/ > Export Results: Precincts CSV > csv on webpage
fileUrl <- "http://results.vote.wa.gov/results/20161108/export/20161108_KitsapPrecincts.csv"
download.file(fileUrl, destfile = file.path(data_folder,"2016_Kitsap_by_precinct.csv"))
kitsap_el <- read_csv(file.path(data_folder,"2016_Kitsap_by_precinct.csv"),
                      col_names = FALSE)

kitsap_data <- kitsap_el %>%
  mutate(Race = factor(X1),
         Precinct = factor(X3),
         Ballots = X5,
         Registered = NA) %>% # no data available for number of registered voters?
  filter(X1 == "President/Vice President",
         X3 != "Total") %>%
  group_by(Precinct) %>%
  summarise(SumOfCount = sum(Ballots),
            Registered = NA,
            County = factor("Kitsap")) %>%
  dplyr::select(County, Precinct, Registered, SumOfCount)

# 3. Pierce County -----
# There are 2 ways to access the data - the first one retrieves data in the same format as Kitsap County (without the number of registered voters), the second one retrieves data in the same format as Snohomish (which requires some transforming)
## Access 1: http://results.vote.wa.gov/results/20161108/pierce/ > Export Results: Precincts CSV > csv on webpage ----
# fileUrl <- "https://results.vote.wa.gov/results/20161108/export/20161108_pierceprecincts.csv"
# download.file(fileUrl, destfile = file.path(data_folder,"2016_Pierce_by_precinct_csv.csv"))
# pierce_csv <- read_csv(file.path(data_folder,"2016_Pierce_by_precinct_csv.csv"),
#                       col_names = FALSE)
## Access 2: https://piercecountywa.gov/DocumentCenter/View/45035/Precinct-Canvass-Excel?bidId= > downloads Precinct Canvass.xls ----
## Saved as: 2016_Pierce_by_precinct.xls
pierce_el <- read_xls(
  file.path(data_folder,"2016_Pierce_by_precinct.xls"),
  sheet = 16) # sheet with president/vice president data

pierce_int <- pierce_el[-c(1:5, 433:438),-c(2, 5:19)] # removing unnecessary rows
names(pierce_int) <- c("Precinct", pierce_int[1,2:ncol(pierce_int)]) # reconfiguring column names
pierce_int <- pierce_int[-1, ] # removing redundant column names
pierce_int[] <- lapply(pierce_int, function(x) type.convert(as.character(x)))

pierce_data <- pierce_int %>%
  mutate(SumOfCount = `Ballots Cast`,
         County = factor("Pierce")) %>%
  dplyr::select(County, Precinct, Registered, SumOfCount)

# 4. Snohomish County -----
## https://www.snohomishcountywa.gov/5737/Get-Current-and-Past-Election-Results-an
## https://www.snohomishcountywa.gov/DocumentCenter/Index/7888 > 2016: November 8, 2016 General Election > Official Precinct Results (Excel): Precinct Canvass_201611291531075278.xls 
## Saved as:  2016_Snohomish_by_precinct.xls
snohomish_el <- read_excel(file.path(data_folder,"2016_Snohomish_by_precinct.xls"), 
                                     sheet = "Sheet10") # President/Vice President sheet

snohomish_int <- snohomish_el[-c(1:5, 780:785),-c(2, 5:19)] # removing unnecessary rows
names(snohomish_int) <- c("Precinct", snohomish_int[1,2:ncol(snohomish_int)]) # reconfiguring column names
snohomish_int <- snohomish_int[-1, ] # removing redundant column names
snohomish_int[] <- lapply(snohomish_int, function(x) type.convert(as.character(x)))


snohomish_data <- snohomish_int %>%
  mutate(SumOfCount = `Ballots Cast`,
         County = factor("Snohomish")) %>%
  dplyr::select(County, Precinct, Registered, SumOfCount)


# 5. Join data -----
civic_eng <- rbind(king_data, kitsap_data, pierce_data, snohomish_data)

vote_data <- civic_eng %>%
  mutate(Precinct = factor(Precinct), 
         County = factor(County),
         CPrecinct = str_c(County, Precinct, sep = "_"))

# Get 2016 precinct shapefile ---------------------
# Access: https://www.sos.wa.gov/elections/data-research/election-data-and-maps/election-results-and-voters-pamphlets > 2016 Elections > General Data (download zip folder: 2016-general-data) > Statewide_Prec_2016_NoWater
# Also available here, but there is no "nowater" option: https://www.sos.wa.gov/elections/data-research/election-data-and-maps/reports-data-and-statistics/precinct-shapefiles > 2016: Statewide_Prec_2016.zip
# Saved: Y:\Equity Indicators\tracker-webpage-content\h-public-services\h02-voter-participation\raw-data\2016\Statewide_Prec_2016_NoWater
all_precinct_data_16 <- read_sf(file.path(data_folder,"Statewide_Prec_2016_NoWater/Statewide_Prec_2016_NoWater.shp"))

# look through shapefile precinct codes
# all_precincts_16 <- as_tibble(all_precinct_data_16)
# glimpse(all_precincts_16)
precinct_16 <- all_precinct_data_16 %>%
  filter(COUNTY %in% c("King", "Kitsap", "Pierce", "Snohomish"))

  #relabel kitsap names to match labels from the election data
kitsap_16 <- precinct_16 %>%
  filter(COUNTY == "Kitsap") %>%
  mutate(last_digits = str_sub(PRECNAME, -3, -1),
         check_digits = ifelse(is.na(as.numeric(last_digits)) == TRUE, 1, 0),
         PRECNAME = ifelse(check_digits == 1, 
                            str_c(PRECNAME, ifelse(nchar(PRECCODE) == 3,
                                  PRECCODE, str_c("0", PRECCODE)), sep = " "),
                            PRECNAME)) %>%
  dplyr::select(-c(last_digits,check_digits))

other_precincts_16 <- precinct_16 %>%
  filter(COUNTY %in% c("King", "Pierce", "Snohomish"))

precinct <- rbind(other_precincts_16, kitsap_16)

precinct_2016  <- precinct  %>%
  mutate(County = factor(COUNTY),
         Precinct = factor(PRECNAME),
         PrecinctCode = factor(PRECCODE),
         CPrecinct = str_c(County, Precinct, sep = "_")) %>%
  dplyr::select(County, PrecinctCode, Precinct, CPrecinct)

precinct_16_sp <- st_transform(precinct_2016, 2285)

# Get 2010 census tract shapefile ---------------------
# Connecting to ElmerGeo for census geographies through Portal----
tracts10.url <- "https://services6.arcgis.com/GWxg6t7KXELn1thE/arcgis/rest/services/Census_Tracts_2010/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson"

tracts10.lyr<-st_read(tracts10.url)
nrow(tracts10.lyr) #773

# join databases  ----------------------------------------------- 
##1 Join precinct gis to elections by precinct
precinct_vote <- precinct_16_sp %>%
  left_join(vote_data, by = ("CPrecinct")) 
  #check join
df <- data.frame(a = c(precinct_vote$CPrecinct))
t <- duplicated(df) | duplicated(df[nrow(df):1, ])[nrow(df):1]
rows <- which(duplicated(df) | duplicated(df[nrow(df):1, ])[nrow(df):1])
# rows <- rows[-1]
  #remove duplicates
precinct <- precinct_vote[-c(rows),]
precinct_sum <- precinct %>%
  mutate(SumOfCount = ifelse(is.na(SumOfCount) == TRUE, 0, SumOfCount))
# table(is.na(precinct_sum$SumOfCount)) #check
```

### 2020 data
The process/code below is adapted from the displacement risk work done in 2020/2021 ("Y:/VISION 2050/Data/Displacement/Displacement Index 2021/data/15-Voter Turnout/"). The 2020 
```{r, include=FALSE}
### Get 2020 presidential election votes by precinct ---------------------
# From: https://www.sos.wa.gov/elections/data-research/2020-general-election-data > "GIS Ready Precinct Results" data download, saved to the equity tracker folder in Y
election = read_excel("Y:/Equity Indicators/tracker-webpage-content/h-public-services/h02-voter-participation/raw-data/2020/2020_precinct_results.xlsx",
                      sheet = "Sheet1")

voters_base <- election %>% 
  dplyr::filter(RaceName == "Turnout",
                Candidate %in% c("Registered Voters", "Ballots Cast"),
                County %in% c("King","Kitsap","Snohomish","Pierce")) %>% 
  dplyr::select(Candidate,PrecinctCode,County,Votes) %>% 
  pivot_wider(names_from = Candidate, values_from = Votes) %>% 
  rename(registered_voters = 'Registered Voters', ballots_cast = 'Ballots Cast')

voters <- voters_base %>%
  mutate(Precinct = factor(PrecinctCode), 
         County = factor(County),
         CPrecinct = str_c(County, Precinct, sep = "_"))

### Get population and number of residential units by parcel ---------------------
mydb = dbConnect(MySQL(), 
                 user='psrcurbansim', 
                 password='psrc_urbansim', 
                 dbname='2018_parcel_baseyear_rtp', 
                 host='aws-modelmysql')

# dbListTables(mydb)

# Total population for each parcel - used to calculate percent of people in precinct who voted
# Join households and buildings to get population per parcel
building_pop = dbGetQuery(mydb, "select building_id, sum(persons) as total_ppl 
                                from households
                                group by building_id")

parcel_data = dbGetQuery(mydb, "select * 
                                from buildings")

pop_by_parcel = parcel_data %>% 
  dplyr::select(building_id, parcel_id) %>% 
  left_join(building_pop,  by = "building_id") %>% 
  group_by(parcel_id) %>% 
  summarise(pop_sum = sum(total_ppl, na.rm = TRUE))

# Total residential units per parcel - used to calculate weight of clipped precinct in tract
resunits_by_parcel = parcel_data %>%
  group_by(parcel_id) %>%
  summarise(resunit_sum = sum(residential_units, na.rm = TRUE))

# Get parcel centroids (X,Y coordinates)
parcel_centroid = dbGetQuery(mydb, "select * from parcels")

# Select only relevant columns and set projection to NAD83 Washington State Plane North (CRS 2285) -> WGS84 (will match other spatial layers later on)
parcel_centroid <- parcel_centroid %>%
  dplyr::select(parcel_id, census_tract_id, x_coord_sp, y_coord_sp) %>% 
  st_as_sf(coords = c("x_coord_sp", "y_coord_sp")) %>% 
  st_set_crs(2285) %>% 
  st_transform(2285) #WGS84: 4326

# plot(parcel_centroid)

# Attach parcel population/residential unit information to parcel centroids
parcel_centroid <- parcel_centroid %>%
  left_join(pop_by_parcel, by = "parcel_id") %>% 
  left_join(resunits_by_parcel, by = "parcel_id") %>%
  # remove NAs 
  filter(!is.na(resunit_sum))

# write_rds(parcel_centroid, "./components/parcel_centroid_pop_resunits.rds")

# rm(mydb, building_pop, parcel_data, pop_by_parcel, resunits_by_parcel)

### Get precinct shapefile for intersections ---------------------
# Access: https://www.sos.wa.gov/elections/data-research/election-data-and-maps/reports-data-and-statistics/precinct-shapefiles > 2020: Statewide_Precincts_2020General.zip
# Saved: Y:\Equity Indicators\tracker-webpage-content\h-public-services\h02-voter-participation\raw-data\2020\Statewide_Precincts_2020General
precinct_data <- read_sf("Y:/Equity Indicators/tracker-webpage-content/h-public-services/h02-voter-participation/raw-data/2020/Statewide_Precincts_2020General/Statewide_Precincts_2020General.shp")

# Retain only PSRC counties, select only relevant columns, set CRS 2285 projection
precinct <- precinct_data %>%
  filter(CountyName %in% c("King", "Kitsap", "Pierce", "Snohomish")) %>%
  mutate(County = factor(County),
         Precinct = factor(PrecName),
         PrecinctCode = factor(PrecCode),
         CPrecinct = str_c(County, Precinct, sep = "_")) %>%
  dplyr::select(County, PrecinctCode, Precinct, CPrecinct, St_Code, geometry) %>%
  st_transform(2285) #2285 4326

# Attach election results to precinct spatial features
precinct_elec <- precinct %>%
  left_join(voters %>% dplyr::select(PrecinctCode, registered_voters, ballots_cast), 
            by = c("St_Code" = "PrecinctCode")) %>% 
  mutate(ballots_cast = replace_na(ballots_cast, 0))

# rm(precinct, voters)


### Get tract shapefile for intersections ---------------------
tracts20.url <- "https://services6.arcgis.com/GWxg6t7KXELn1thE/arcgis/rest/services/Census_Tracts_2020/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson"
# tracts10.url <- "https://services6.arcgis.com/GWxg6t7KXELn1thE/arcgis/rest/services/Census_Tracts_2010/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson"

tracts20.lyr<-st_read(tracts20.url)
# tracts10.lyr<-st_read(tracts10.url)

# tract <- read_sf("Y:/VISION 2050/Data/Displacement/Displacement_Risk_Script/gis/tract2010_nowater.shp")
# Set correct projection
tract <- tracts20.lyr %>%
  mutate(GEOID = factor(geoid20)) %>%
  st_transform(2285) # transform to match the coordinates of the precinct centroids (need to change back later)
```

```{r}
### Spatial intersections

# PRECINCT/PARCEL: Intersect parcel centroids with precinct spatial feature - yields number of people and residential units in each precinct
precinct_parcel = st_join(precinct_elec, parcel_centroid)
# 25 precincts have no parcels or residential units, so the parcel columns are NA. Make these zero to indicate absence of population/residential units
precinct_parcel$pop_sum <- replace_na(precinct_parcel$pop_sum, 0)
precinct_parcel$resunit_sum <- replace_na(precinct_parcel$resunit_sum, 0)

# Sum up population and total residential by precinct
precinct_pop = precinct_parcel %>%
  # Do not need spatial features to calculate population/total res. units by parcel, and runs faster making geometry NULL
  st_set_geometry(NULL) %>% 
  group_by(St_Code) %>% 
  summarise(precinct_pop = sum(pop_sum),
            precinct_resunit = sum(resunit_sum))

# rm(precinct_parcel)

# Attach population/resunit totals to precinct spatial features/election info
# Then can calculate "turnout", or number of votes out of all people living in the precinct (not just eligible voters)
# Note adding 1 to precinct_pop to avoid zero divide
precinct_pop <- precinct_elec %>% 
  left_join(precinct_pop, by = "St_Code" ) %>% 
  mutate(turnout = ballots_cast/(precinct_pop + 1),
         # 64 precincts have more ballots cast than population. Cap turnout at 1 (100%)
         turnout = ifelse(turnout > 1, 1, turnout)) 

# rm(precinct_elec)
# write_rds(precinct_pop, "./components/precinct_turnout_cap100.rds")

# PRECINCT/TRACT: Intersect precinct and tract spatial features to yield clipped precincts
precinct_tract <- st_intersection(precinct_pop, tract) %>% 
  # Add ids to clipped precincts to group on later
  mutate(id = row_number())

# rm(precinct_pop)

# PARCELS/CLIPPED PRECINCTS: Intersect parcel centroids with clipped precincts - yields number of people and residential units in each clipped precinct
precinct_tract_parcel = st_join(precinct_tract, parcel_centroid)

# rm(parcel_centroid)

# summary(precinct_tract_parcel$pop_sum) #5109 NAs
# summary(precinct_tract_parcel$resunit_sum) #5109 NAs
# 5109 clipped precincts have no parcels, so the parcel columns are NA. Change total population and residential units to 0
precinct_tract_parcel$pop_sum <- precinct_tract_parcel$pop_sum %>% replace_na(0)
precinct_tract_parcel$resunit_sum <- precinct_tract_parcel$resunit_sum %>% replace_na(0)

# Count all residential units in clipped precinct
precinct_tract_population = precinct_tract_parcel %>% 
  st_set_geometry(NULL) %>% 
  group_by(id) %>% 
  summarise(precinct_resunit_int = sum(resunit_sum)) 

# rm(precinct_tract_parcel)

# Attach total residential units to clipped precinct spatial features and data
precinct_tract_pop <- precinct_tract %>% 
  left_join(precinct_tract_population, by = "id" )

# rm(precinct_tract_population)

# WEIGHTS: Calculate total residential units in each tract by grouping clipped precincts by tract
tractresunit <- precinct_tract_pop %>% 
  st_set_geometry(NULL) %>% 
  group_by(GEOID) %>% 
  summarise(tractresunit = sum(precinct_resunit_int))

cntyresunit <- precinct_tract_pop %>% 
  st_set_geometry(NULL) %>% 
  group_by(county_name) %>% 
  summarise(cntyresunit = sum(precinct_resunit_int))

regresunit <- precinct_tract_pop %>% 
  st_set_geometry(NULL) %>% 
  # group_by(county_name) %>% 
  summarise(regresunit = sum(precinct_resunit_int))

# Attach total residential units by tract to clipped precincts, calculate weights as (# resunits clipped precinct)/(# resunits in tract + 1)
# One tract has no residential units, so add 1 to tractresunit
precinct_tract_wt <- precinct_tract_pop %>%
  left_join(tractresunit, by = "GEOID") %>%
  mutate(weight = precinct_resunit_int/(tractresunit + 1),
         weighted_vote = weight * turnout)

precinct_cnty_wt <- precinct_tract_pop %>%
  left_join(cntyresunit, by = "county_name") %>%
  mutate(weight = precinct_resunit_int/cntyresunit,
         weighted_vote = weight * turnout)

precinct_reg_wt <- precinct_tract_pop %>%
  # left_join(regresunit, by = "county_name") %>%
  mutate(weight = precinct_resunit_int/regresunit$regresunit,
         weighted_vote = weight * turnout)

# FINAL VALUES: Calculate turnout score by tract as weighted sum of turnout in clipped precincts
# tabular data
votes_tract <- precinct_tract_wt %>%
  st_set_geometry(NULL) %>%
  group_by(GEOID) %>%
  summarise(votes = sum(weighted_vote, na.rm = TRUE) * 100)

votes_cnty <- precinct_cnty_wt %>% 
  st_set_geometry(NULL) %>% 
  group_by(county_name) %>% 
  summarise(votes_cnty = sum(weighted_vote, na.rm = TRUE) *100)

votes_reg <- precinct_reg_wt %>% 
  st_set_geometry(NULL) %>%
  summarise(votes_reg = sum(weighted_vote, na.rm = TRUE) *100)

# Join tabular data to tract (need common fields), transform to data frame
tract_votes_df <- tract %>%
  left_join(votes_tract, by = ("GEOID")) %>% 
  left_join(votes_cnty, by = ("county_name")) %>% 
  mutate(votes_reg = votes_reg$votes_reg)%>%
  st_set_geometry(NULL) #keep in tabular form (remove geometry)

# votes_tract_viz <- precinct_tract %>%
#   st_set_geometry(NULL) %>%
#   group_by(GEOID) %>%
#   summarise(votes = sum(weighted_vote, na.rm = TRUE),
#             precincts = toString(St_Code),
#             clipped_resunits = toString(precinct_resunit_int),
#             turnouts = (round(turnout,2)) * 100)

# rm(precinct_tract, tractresunit)
```
\
Currently we are only using 2020 election data.  


## Additional data

### equity quintile data and 2010-20 crosswalk file 

* low, low medium, etc.) at the tract-level for each equity focus group for the years that correspond to the life expectancy data (2010, 2015, 2020
* for the 2016-2020 life expectancy data set
```{r, include=FALSE}
# Elmer data sets - equity quintile tracts using psrcelmer() and crosswalk
equity_tracts <- get_table(schema="equity", tbl_name="v_tract_shares")
table(equity_tracts$data_year)

# don't need crosswalk for this dataset but will leave in code for now
crosswalk_10_20 <- get_table(schema="census",
                             tbl_name="v_geo_relationships_tracts")
```


# Explore data
The 2010 and 2015 equity tracts are in 2010 geographies and include ~770 census tracts, each of which are assigned one of the 5 quintile categories for each of the 6 equity demographic groups. The 2010, 2015, an 2020 life expectancy data are available from WTN in 2010 geographies, so the 2020-year data will need to be translated to 2020 geographies to be able to use the 2020 population information.
```{r, include=FALSE}
# check number of rows in data sets
nrow(tract_votes_df) #919 - number of census tracts
summary(tract_votes_df$votes)
```

## Most Recent Data
### Map
#### Join recent data to spatial file
```{r, include=FALSE}
# Join tabular data to tract spatial data
tract_votes <- tract %>%
  left_join(votes_tract, by = ("GEOID")) %>% 
  left_join(votes_cnty, by = ("county_name")) %>% 
  mutate(votes_reg = votes_reg$votes_reg)%>%
  st_transform(4326)

# consistent field names
data_tract <- tract_votes %>% 
  dplyr::rename(estimate=votes,
                reg_estimate=votes_reg,
                cnty_estimate=votes_cnty)

```

```{r}
# https://stackoverflow.com/questions/40276569/reverse-order-in-r-leaflet-continuous-legend - to get legend high-low with correct color order
addLegend_decreasing <-
  function (map,
            position = c("topright", "bottomright", "bottomleft",
                         "topleft"),
            pal,
            values,
            na.label = "NA",
            bins = 7,
            colors,
            opacity = 0.5,
            labels = NULL,
            labFormat = labelFormat(),
            title = NULL,
            className = "info legend",
            layerId = NULL,
            group = NULL,
            data = getMapData(map),
            decreasing = FALSE) {
    position <- match.arg(position)
    type <- "unknown"
    na.color <- NULL
    extra <- NULL
    if (!missing(pal)) {
      if (!missing(colors))
        stop("You must provide either 'pal' or 'colors' (not both)")
      if (missing(title) && inherits(values, "formula"))
        title <- deparse(values[[2]])
      values <- evalFormula(values, data)
      type <- attr(pal, "colorType", exact = TRUE)
      args <- attr(pal, "colorArgs", exact = TRUE)
      na.color <- args$na.color
      if (!is.null(na.color) &&
          col2rgb(na.color, alpha = TRUE)[[4]] ==
          0) {
        na.color <- NULL
      }
      if (type != "numeric" && !missing(bins))
        warning("'bins' is ignored because the palette type is not numeric")
      if (type == "numeric") {
        cuts <- if (length(bins) == 1)
          pretty(values, bins)
        else
          bins
        
        if (length(bins) > 2)
          if (!all(abs(diff(bins, differences = 2)) <=
                   sqrt(.Machine$double.eps)))
            stop("The vector of breaks 'bins' must be equally spaced")
        n <- length(cuts)
        r <- range(values, na.rm = TRUE)
        cuts <- cuts[cuts >= r[1] & cuts <= r[2]]
        n <- length(cuts)
        p <- (cuts - r[1]) / (r[2] - r[1])
        extra <- list(p_1 = p[1], p_n = p[n])
        p <- c("", paste0(100 * p, "%"), "")
        if (decreasing == TRUE) {
          colors <- pal(rev(c(r[1], cuts, r[2])))
          labels <- rev(labFormat(type = "numeric", cuts))
        } else{
          colors <- pal(c(r[1], cuts, r[2]))
          labels <- rev(labFormat(type = "numeric", cuts))
        }
        colors <- paste(colors, p, sep = " ", collapse = ", ")
        
      }
      else if (type == "bin") {
        cuts <- args$bins
        n <- length(cuts)
        mids <- (cuts[-1] + cuts[-n]) / 2
        if (decreasing == TRUE) {
          colors <- pal(rev(mids))
          labels <- rev(labFormat(type = "bin", cuts))
        } else{
          colors <- pal(mids)
          labels <- labFormat(type = "bin", cuts)
        }
        
      }
      else if (type == "quantile") {
        p <- args$probs
        n <- length(p)
        cuts <- quantile(values, probs = p, na.rm = TRUE)
        mids <- quantile(values, probs = (p[-1] + p[-n]) / 2,
                         na.rm = TRUE)
        if (decreasing == TRUE) {
          colors <- pal(rev(mids))
          labels <- rev(labFormat(type = "quantile", cuts, p))
        } else{
          colors <- pal(mids)
          labels <- labFormat(type = "quantile", cuts, p)
        }
      }
      else if (type == "factor") {
        v <- sort(unique(na.omit(values)))
        colors <- pal(v)
        labels <- labFormat(type = "factor", v)
        if (decreasing == TRUE) {
          colors <- pal(rev(v))
          labels <- rev(labFormat(type = "factor", v))
        } else{
          colors <- pal(v)
          labels <- labFormat(type = "factor", v)
        }
      }
      else
        stop("Palette function not supported")
      if (!any(is.na(values)))
        na.color <- NULL
    }
    else {
      if (length(colors) != length(labels))
        stop("'colors' and 'labels' must be of the same length")
    }
    legend <-
      list(
        colors = I(unname(colors)),
        labels = I(unname(labels)),
        na_color = na.color,
        na_label = na.label,
        opacity = opacity,
        position = position,
        type = type,
        title = title,
        extra = extra,
        layerId = layerId,
        className = className,
        group = group
      )
    invokeMethod(map, data, "addLegend", legend)
  }

```

```{r tract data map}
# set map extent
map.lat<- 47.615
map.lon<- -122.257
map.zoom<- 8.5

# set up palettes
psrc_palette <- leaflet::colorNumeric(palette=psrc_colors$purples_inc,
                                      domain = data_tract$estimate)

# set the variable
var_name <- "Voter Participation"

# map settings
tract_map <- leaflet() %>%
  leaflet::addMapPane(name = "polygons", zIndex = 410) %>%
  leaflet::addMapPane(name = "maplabels", zIndex = 500) %>% # higher zIndex rendered on top
  leaflet::addProviderTiles("CartoDB.VoyagerNoLabels") %>%
  leaflet::addProviderTiles("CartoDB.VoyagerOnlyLabels",
                            options = leaflet::leafletOptions(pane = "maplabels"),
                            group = "Labels") %>%
  addPolygons(data=data_tract,
              fillColor = psrc_palette(data_tract$estimate),
              stroke=FALSE, 
              smoothFactor = 0.2,
              fillOpacity = 0.7,
              group = var_name,
              label = round(data_tract$estimate, digits=1)) %>%

  # legends
  addLegend_decreasing(pal = psrc_palette,
                       values = data_tract$estimate,
                       position = "bottomright",
                       title = var_name,
                       group = var_name,
                       opacity = 0.7,
                       decreasing = TRUE,
                       labFormat = labelFormat()) %>% 
  
  #set view extent
  leaflet::setView(lng=map.lon, lat=map.lat, zoom=map.zoom) %>% 
  addEasyButton(easyButton(
    icon = htmltools::span(class = "globe", htmltools::HTML("&#127758;")),  #&#127760; (another emoji option) #"fa-globe", (font awesome icon no longer works because of the conversion to Poppins font below)   
    title ="Region",
    onClick=JS("function(btn, map){map.setView([47.615,-122.257],8.5); }")))

# fix the legend NA placement (https://github.com/rstudio/leaflet/issues/615)
css_fix <- "div.info.legend.leaflet-control br {clear: both;} html * {font-family: Poppins !important;}" # CSS to correct spacing and font family
html_fix <- htmltools::tags$style(type = "text/css", css_fix)  # Convert CSS to HTML
tract_map %<>% htmlwidgets::prependContent(html_fix)

# print map
tract_map
```

### Missing Data
Life expectancy calculations can fluctuate considerably in smaller populations or populations experiencing low or no deaths for the year(s) being calculated. Because of these issues the Life Expectancy at birth calculation for the Census Tract geographies is suppressed for Census Tracts with a population (for the 5 years combined) of <5000 or a result with a Standard Error >2 or a record of <50 deaths for the time period. The Washington Department of Health, Center for Health Statistics estimates data gathered from death certificates to be 99% complete.

#### Isolate NA or missing data
```{r}
# join NA data to the shapefile to map
data_tract_na <- data_tract %>% 
  filter(is.na(estimate))

nrow(data_tract_na) #0 tracts
```

```{r missing tract map}
# set map extent
map.lat<- 47.615
map.lon<- -122.257
map.zoom<- 8.5

# set up palettes
psrc_palette <- leaflet::colorNumeric(palette=psrc_colors$purples_inc,
                                      domain = data_tract$estimate)

# set the variable
var_name <- "Voter Participation"

# map settings
tract_map <- leaflet() %>%
  leaflet::addMapPane(name = "polygons", zIndex = 410) %>%
  leaflet::addMapPane(name = "maplabels", zIndex = 500) %>% # higher zIndex rendered on top
  leaflet::addProviderTiles("CartoDB.VoyagerNoLabels") %>%
  leaflet::addProviderTiles("CartoDB.VoyagerOnlyLabels",
                            options = leaflet::leafletOptions(pane = "maplabels"),
                            group = "Labels") %>%
  leaflet::addLayersControl(baseGroups = var_name,
                   overlayGroups = "missing data",
                   options = layersControlOptions(collapsed = FALSE)) %>%
  
  addPolygons(data=data_tract,
              fillColor = psrc_palette(data_tract$estimate),
              stroke=FALSE, 
              smoothFactor = 0.2,
              fillOpacity = 0.7,
              group = var_name,
              label = round(data_tract$estimate, digits=1)) %>%
  addPolygons(data=data_tract_na,
              color = "red",
              stroke = TRUE, 
              weight = 3,
              smoothFactor = 0.5,
              fillOpacity = 0,
              group = "missing data") %>% 

  # legends
  addLegend_decreasing(pal = psrc_palette,
                       values = data_tract$estimate,
                       position = "bottomright",
                       title = var_name,
                       group = var_name,
                       opacity = 0.7,
                       decreasing = TRUE,
                       labFormat = labelFormat()) %>% 
  
  #set view extent
  leaflet::setView(lng=map.lon, lat=map.lat, zoom=map.zoom) %>% 
  addEasyButton(easyButton(
    icon = htmltools::span(class = "globe", htmltools::HTML("&#127758;")),  #&#127760; (another emoji option) #"fa-globe", (font awesome icon no longer works because of the conversion to Poppins font below)   
    title ="Region",
    onClick=JS("function(btn, map){map.setView([47.615,-122.257],8.5); }")))

# fix the legend NA placement (https://github.com/rstudio/leaflet/issues/615)
css_fix <- "div.info.legend.leaflet-control br {clear: both;} html * {font-family: Poppins !important;}" # CSS to correct spacing and font family
html_fix <- htmltools::tags$style(type = "text/css", css_fix)  # Convert CSS to HTML
tract_map %<>% htmlwidgets::prependContent(html_fix)

# print map
tract_map
```

### Descriptive Statistics
The following descriptive statistics reflect the census tracts that have values - the `r na_rows_num` census tracts with NAs have been removed. These are not weighted by population numbers. 
```{r}
data_tract_nona <- data_tract %>% 
  filter(!is.na(estimate))

summary(data_tract_nona$estimate)
```

**When weighted by tract populations.** 
```{r, include=FALSE}
distrib <- rep(data_tract_nona$estimate, 1)
```
\
\

#### Histogram
A histogram is a visual representation of the distribution of a dataset...The y-axis shows how frequently the values on the x-axis occur in the data, while the bars group ranges of values or continuous categories on the x-axis [(source)](https://www.datacamp.com/tutorial/make-histogram-basic-r).  
```{r}
hist(distrib)
```
\

#### Boxplot
A boxplot helps to visualize a quantitative variable by displaying five common location summary (minimum, median, first and third quartiles and maximum) and any observation that was classified as a suspected outlier using the interquartile range (IQR) criterion [(source)](https://statsandr.com/blog/outliers-detection-in-r/).  
```{r}
boxplot(distrib, horizontal = TRUE)
```
\

#### Outliers
The IQR criterion means that all observations above or below the first and third quartile respectively, and IQR is the difference between the third and first quartile) are considered as potential outliers by R [(source)](https://statsandr.com/blog/outliers-detection-in-r/).  
```{r}
outliers <- boxplot.stats(distrib)$out
outlier_rle <- rle(outliers)
outlier_df <- data.frame(unclass(outlier_rle)) %>% 
  rename(population = lengths,
         health_in = values) %>% 
  arrange(health_in)

outlier_df
```
\

##### *Check outliers*
The following steps are specific to the life expectancy dataset and may or may not be applicable depending on the data.

###### Identify census tracts with outliers
```{r include=FALSE}
outlier_values <- outlier_df[,2]

data_tract_nona_outliers <- data_tract_nona %>% 
  dplyr::filter(estimate %in% outlier_values)

num_outliers <- nrow(data_tract_nona_outliers) #9
```
There are `r num_outliers` tracts that have outliers. 
\
\

###### Outliers by Displacement Risk score
This check uses the displacement risk data, which is mapped to 2010 census tracts. This will help determine if there is a connection between displacement risk and `r indicator_measure`.
```{r displacement risk data, inlcude=FALSE}
# Connecting to Portal for displacement tract geographies ----
displacement.url <- "https://services6.arcgis.com/GWxg6t7KXELn1thE/arcgis/rest/services/Displacement_Risk_Data/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson"

displacement.lyr <-st_read(displacement.url)
# head(displacement.lyr)
# plot(displacement.lyr$geometry)
# class(displacement.lyr$geoid10)

displacement_simp <- displacement.lyr %>%
  dplyr::select(geoid10,
                risk_score) %>% 
  as_tibble() %>% 
  dplyr::select(-geometry)

# convert displacement data to 2020 census tract geographies to match indicator
displacement_20<- merge(x=displacement_simp, 
                        y=crosswalk_10_20,
                        by.x="geoid10",
                        by.y="geoid10",
                        all.y=TRUE)
```

```{r, include=FALSE}
data_tract_nona_outliers %<>% 
  dplyr::mutate(geoid=trimws(geoid20))

# join outlier tract datas to spatial dispalcement tract data to isolate tracts with outlier data
data_tract_risk_outliers <- merge(x=displacement_20, 
                                  y=data_tract_nona_outliers,
                                  by.x="geoid20",
                                  by.y="geoid20",
                                  all.y=TRUE)
head(data_tract_risk_outliers)
# class(data_tract_risk_outliers)
# plot(data_tract_risk_outliers$geometry)
nrow(data_tract_risk_outliers) #9
pop_outliers <- as.numeric(sum(data_tract_risk_outliers$total_pop20, na.rm = T)) #48784
pop_outliers_num <- label_comma()(pop_outliers)
```
There are `r pop_outliers_num` people (2020 Decennial Census) in these outlier tracts.
\
\
```{r}
# compare the two measures
plot(data_tract_risk_outliers$risk_score, 
     data_tract_risk_outliers$estimate)
```

```{r}
# this will be different for each indicator - the code and the text included below...
# based on the plot in the last chunk, this code is meant to isolate outlier(s) - in this case it filters for the outliers with high risk scores and high life expectancy

# outlier #1
data_tract20_outliers_1 <- data_tract_risk_outliers %>% 
  filter(risk_score > 50)

# code to look at the scores and census tracts that are outliers
data_tract20_outliers_1

# outlier #2
data_tract20_outliers_2 <- data_tract_risk_outliers %>% 
  filter(risk_score < 17)

# code to look at the scores and census tracts that are outliers
data_tract20_outliers_2

# To locate the census tracts on the map, its easy to use the Data Portal (https://psrc-psregcncl.hub.arcgis.com/datasets/census-tracts-2020/explore?location=47.506129%2C-121.980700%2C9.23) - just filter on the geoid20 field. 
```


# **MAP .rda**
Save final data set (.rda) for map
```{r}
# set folder structure
base_dir <- 'Y:/Equity Indicators/tracker-webpage-content'
theme_dir <- 'h-public-services'
ind_dir <- 'h02-voter-participation'
file_name <- 'h02-voter-participation-data'

# save final data set as .rda
save(data_tract, file = file.path(base_dir,
                                  theme_dir,
                                  ind_dir, "rda-data",
                                  paste0(file_name,'.rda')))
```

# Explore data by equity quintile
## Join primary data to equity quintiles and acs population
```{r}
# # 2010 data -----
# equity_tracts_10 <- equity_tracts %>% 
#   dplyr::filter(data_year==2010)
# 
# # join WTN data to equity quintiles (on 2010 census tracts)
# data_equity_tracts <- merge(life_expec_06_10, equity_tracts_10,
#                             by.x="Census.Tract",
#                             by.y="geoid", 
#                             all.x=TRUE)
# 
# # join 2010 acs population data to WTN data - this is for eventual weighting (which may not be necessary depending on the indicator)
# data_equity_tract10 <- merge(tract.10, data_equity_tracts,
#                              by.x="GEOID",
#                              by.y="Census.Tract", 
#                              all.x=TRUE)
# 
# # check data set
# nrow(data_equity_tract10) #1548
```
This data set should include about twice the number of census tracts in the region - census tracts are listed twice - once as part of the region and another as part of their corresponding county.

```{r}
# # 2015 data ----- 
# equity_tracts_15 <- equity_tracts %>% 
#   dplyr::filter(data_year==2015)
# 
# # join WTN data to equity quintiles (on 2010 census tracts)
# data_equity_tracts <- merge(life_expec_11_15, equity_tracts_15,
#                             by.x="Census.Tract",
#                             by.y="geoid", 
#                             all.x=TRUE)
# 
# # join 2015 acs population data to WTN data - this is for eventual weighting (which may not be necessary depending on the indicator)
# data_equity_tract15 <- merge(tract.15, data_equity_tracts,
#                              by.x="GEOID",
#                              by.y="Census.Tract", 
#                              all.x=TRUE)
# 
# # check data set
# nrow(data_equity_tract15)
```
This data set should include about twice the number of census tracts in the region - census tracts are listed twice - once as part of the region and another as part of their corresponding county.

```{r}
# 2020 data -----
equity_tracts_20 <- equity_tracts %>% 
  dplyr::filter(data_year==2020)

nrow(equity_tracts_20) #1838: because the census tracts are categorized by county and then by region, so each one (919) is represented twice
# checking to make sure that it matches the 2020 geography
n_distinct(equity_tracts_20$geoid) #919

# # join WTN data (in 2010 census tracts) to cross walk
# data_crosswalk <- merge(crosswalk_10_20, life_expec_16_20,
#                         by.x="geoid10",
#                         by.y="Census.Tract",
#                         all.x=TRUE)

# join tract data to equity quintiles (on 2020 census tracts)
data_equity_tract20 <- merge(tract_votes_df, equity_tracts_20,
                             by.x="geoid20",
                             by.y="geoid", 
                             all.y=TRUE)
# nrow(data_equity_tracts)

# # join 2020 acs population data to WTN data - this is for eventual weighting (which may not be necessary depending on the indicator)
# data_equity_tract20 <- merge(tract.20, data_equity_tracts,
#                              by.x="GEOID",
#                              by.y="geoid20", 
#                              all.x=TRUE)

# # check data set
# nrow(data_equity_tract20)
```
This data set should include about twice the number of census tracts in the region - census tracts are listed twice - once as part of the region and another as part of their corresponding county.

## Transform/pivot
The data sets need to be cleaned and pivoted to a longer table so that there is only one field for the 6 different equity categories, instead of one field for each.
```{r, include=FALSE}
# # clean/simplify data sets
# data_equity_quintiles10 <- data_equity_tract10 %>% 
#   dplyr::mutate(data_year=format(year.x,format="%Y")) %>% 
#   dplyr::mutate(Life.Expectancy_num=as.numeric(Life.Expectancy))
# 
# data_equity_quintiles15 <- data_equity_tract15 %>% 
#   dplyr::mutate(data_year=format(year.x,format="%Y")) %>% 
#   dplyr::mutate(Life.Expectancy_num=as.numeric(Life.Expectancy))

data_equity_quintiles20 <- data_equity_tract20 %>% 
  dplyr::mutate(data_year=format(data_year,format="%Y"))

# # pivot data set so that there is one column with quintile designation
# data_equity_pivot10 <- data_equity_quintiles10 %>% 
#   pivot_longer(cols = poc_quintile:lep_quintile,
#                names_to = "equity_group",
#                values_to = "quintile")
# 
# data_equity_pivot15 <- data_equity_quintiles15 %>% 
#   pivot_longer(cols = poc_quintile:lep_quintile,
#                names_to = "equity_group",
#                values_to = "quintile")

data_equity_pivot20 <- data_equity_quintiles20 %>% 
  pivot_longer(cols = poc_quintile:lep_quintile,
               names_to = "equity_group",
               values_to = "quintile")
```

```{r}
# # check data sets
# nrow(data_equity_pivot10)
# nrow(data_equity_pivot15)
nrow(data_equity_pivot20) #11028
```

These data sets should include records for:

* 2 geographies (region and whichever county the tract belongs to) x # census tracts (~773 for 2010/15, ~919 for 2020)
* 6 equity focus groups (disability and lep are not available in for 2010, lep not available in 2015 - but still show up as NA)


## Calculations
### Calculate by region
The life expectancy values are available at the census tract level, but we want to calculate the regional average, using the census bureau's tract-level population estimates (2010, 2015, 2020).
```{r}
# data_equity_pivot10_calc <- data_equity_pivot10 %>% 
#   filter(!is.na(quintile)) %>% #missing lep and disability data
#   dplyr::group_by(equity_group, quintile) %>%
#   summarise(wt_life_expec=(sum(Life.Expectancy_num*estimate, na.rm =TRUE))/(sum(estimate, na.rm=TRUE))) %>% 
#   mutate(County.Name="Region") %>% 
#   mutate(data_year=2010)
# 
# data_equity_pivot15_calc <- data_equity_pivot15 %>% 
#   filter(!is.na(quintile)) %>% #missing lep data
#   dplyr::group_by(equity_group, quintile) %>%
#   summarise(wt_life_expec=(sum(Life.Expectancy_num*estimate, na.rm =TRUE))/(sum(estimate, na.rm=TRUE))) %>% 
#   mutate(County.Name="Region") %>% 
#   mutate(data_year=2015)

data_equity_pivot20_calc <- data_equity_pivot20 %>% 
  filter(!is.na(quintile)) %>%
  dplyr::group_by(equity_group, quintile) %>%
  summarise(estimate=(mean(votes, na.rm =TRUE))/100, .groups='drop') %>% #need to revert back to decimal for chart function to be set to "percent"
  mutate(county_name="Region") %>% 
  mutate(data_year=2020)
```

```{r}
# # check data sets
# nrow(data_equity_pivot10_calc)
# nrow(data_equity_pivot15_calc)
nrow(data_equity_pivot20_calc) #30
```
These data sets should include records for:

* 1 geography: region
* 6 equity focus groups (disability and lep are not available in for 2010, lep not available in 2015)
     * 2010: only 4 equity focus groups
     * 2015: only 5 equity focus groups
* 5 equity quintiles 


### Calculate by equity quintile
The voter particiaption values are available at the census tract level but we want to calculate the values by the 6 equity/5 quintile groups. Because we only have one year of data (2020), the additional chunks that aren't relative will be commented out 
```{r}
# # calculate 2010 region population
# population_test <- data_equity_pivot10 %>% 
#   distinct(GEOID, .keep_all = TRUE) %>%
#   dplyr::summarise(pop=formatC((sum(estimate, na.rm=TRUE)), format="d", big.mark=",")) #3,603,425
# 
# sum(tract.10$estimate) #3,603,425
# 
# # calculations to get weighted average life expectancy
# data_equity_wt10 <- data_equity_pivot10 %>% 
#   filter(!is.na(quintile)) %>% # necessary because of added na columns from pivot
#   dplyr::mutate(tot_risk_tract=estimate*Life.Expectancy_num) %>% 
#   dplyr::group_by(County.Name, data_year, equity_group, quintile) %>%
#   dplyr::summarise(tracts=length(GEOID),
#                    tot_age=(sum(tot_risk_tract, na.rm = TRUE)),
#                    tot_pop=(sum(estimate, na.rm = TRUE))) %>% 
#   dplyr::mutate(wt_life_expec=tot_age/tot_pop)
# 
# # # check population
# # data_equity_wt10_test <- data_equity_wt10 %>% 
# #   dplyr::filter(equity_group=="income_quintile")
# # sum(data_equity_wt10_test$tot_pop) #3,603,425
# 
# # check data set
# nrow(data_equity_wt10)
```
The regional population in 2010: `r population_test`
\
\
This data sets should include records for:

* 4 geographies: 4 PSRC counties
* 4 equity focus groups (disability and lep are not available in for 2010)
* 5 equity quintiles 

```{r}
# # calculate 2015 region population
# population_test <- data_equity_pivot15 %>% 
#   distinct(GEOID, .keep_all = TRUE) %>%
#   dplyr::summarise(pop=formatC((sum(estimate, na.rm=TRUE)), format="d", big.mark=",")) #3,869,802
# 
# # calculations to get weighted average life expectancy
# data_equity_wt15 <- data_equity_pivot15 %>% 
#   filter(!is.na(quintile)) %>% # necessary because of added na columns from pivot
#   dplyr::mutate(tot_risk_tract=estimate*Life.Expectancy_num) %>% 
#   dplyr::group_by(County.Name, data_year, equity_group, quintile) %>%
#   dplyr::summarise(tracts=length(GEOID),
#                    tot_age=(sum(tot_risk_tract, na.rm = TRUE)),
#                    tot_pop=(sum(estimate, na.rm = TRUE))) %>% 
#   dplyr::mutate(wt_life_expec=tot_age/tot_pop)
# 
# # # check population
# # data_equity_wt15_test <- data_equity_wt15 %>%
# #   dplyr::filter(equity_group=="income_quintile")
# # sum(data_equity_wt15_test$tot_pop) #3,869,802
# 
# # check data set
# nrow(data_equity_wt15)
```
The regional population in 2015: `r population_test`
\
\
This data sets should include records for:

* 4 geographies: 4 PSRC counties
* 5 equity focus groups (lep not available in 2015)
* 5 equity quintiles 

```{r}
# calculations to get average value per equity group/quintile
data_equity_20 <- data_equity_pivot20 %>% 
  filter(!is.na(quintile)) %>% # necessary because of added na columns from pivot
  # dplyr::mutate(tot_risk_tract=estimate*Life.Expectancy_num) %>% 
  dplyr::group_by(county_name, data_year, equity_group, quintile) %>%
  dplyr::summarise(estimate=(mean(votes, na.rm =TRUE))/100, .groups='drop') #need to revert back to decimal for chart function to be set to "percent"

# check data set
nrow(data_equity_20) #119
```
The regional population in 2020: `r population_test`
\
\
This data sets should include records for:

* 4 geographies: 4 PSRC counties
* 6 equity focus groups
* 5 equity quintiles 

## Combine years into one data set
```{r}
# combine region and county data
# data_tract <- as.data.frame(rbind(data_equity_wt10,
#                                   data_equity_wt15,
#                                   data_equity_wt20)) %>%
#   dplyr::select(-tot_age, -tot_pop, -tracts) %>%
#   rbind(data_equity_pivot10_calc,
#         data_equity_pivot15_calc,
#         data_equity_pivot20_calc) %>%
#   filter(!is.na(quintile))

data_tract <- as.data.frame(rbind(data_equity_pivot20_calc,
                                  data_equity_20))

# check data set
str(data_tract)
```
This data set should include records for: 

* 5 geographies: 4 PSRC counties + region
* 3 years
* 6 equity focus groups
    * 2010: (subtracting) 2 missing focus groups(disability, lep) * 5 equity quintiles * 5 geographies
    * 2015: (subtracting) 1 missing focus group (lep) * 5 equity quintiles * 5 geographies
* 5 equity quintiles

## Rename and factor
```{r}
# wrap/order labels ----
county_order <- c("Region", "King", "Kitsap", "Pierce", "Snohomish")

quintile_order <- c("Low", 
                    "Low\nMedium", 
                    "Medium", 
                    "Medium\nHigh", 
                    "High")

equity_group_order <- c("People of Color", 
                        "Households with Lower Income", 
                        "People with a Disability", 
                        "Households with Limited English Proficiency", 
                        "Households with Youth <18", 
                        "Households with Older Adults 65+")

# transforming data labels ----
data_clean <- data_tract %>% 
  mutate(county=county_name) %>%  #rename value variable for consistency
  mutate(county_ord = factor(county, levels=county_order)) %>%
  mutate(equity_group_ord = case_when(
    equity_group=="poc_quintile"~"People of Color",
    equity_group=="disability_quintile"~"People with a Disability",
    equity_group=="lep_quintile"~"Households with Limited English Proficiency",
    equity_group=="income_quintile"~"Households with Lower Income",
    equity_group=="youth_quintile"~"Households with Youth <18",
    equity_group=="older_quintile"~"Households with Older Adults 65+")) %>%
  mutate(equity_group_ord = factor(equity_group_ord, levels = equity_group_order)) %>% 
  mutate(quintile_ord = str_wrap(quintile, width=7)) %>%
  mutate(quintile_ord = factor(quintile_ord, levels = quintile_order))

# Sort the data to ensure the charts work
data_clean <- data_clean %>%
  arrange(county_ord, equity_group_ord, quintile_ord, data_year)
```


# **CHART .rda**
Save final data set for charts (.rda)
```{r}
# set folder structure
file_name <- 'h02-voter-participation-data'

# save final data set as .rda
save(data_clean, file = file.path(base_dir,
                                  theme_dir,
                                  ind_dir, "rda-data",
                                  paste0(file_name,'.rda')))
```

<a href="#top">Back to top of the page</a>